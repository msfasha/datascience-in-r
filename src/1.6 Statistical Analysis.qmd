---
title: "1.6 Statistical Analysis"
format: html
editor: visual
include-before: |
  <div style="text-align: center;">
    <img src="images/department_logo.png" width="169" />
    <img src="images/ioa_logo.png" width="122" />
    <img src="images/petra_logo.png" width="52" />
  </div>
---

Open the sample dataset

```{r}
library(dplyr)
library(readr)

file_path <- "data\\superstore.csv"
superstore <- read_csv(file_path, show_col_types = FALSE)
```

### 1. Correlation Analysis

**Introduction**: - Correlation analysis measures the strength and direction of the relationship between two variables. For instance, you can analyze the correlation between sales and profit, or discount and profit.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(GGally)  
# Select relevant numeric columns 
numeric_data <- superstore %>%   select(Sales, Profit, Discount, Quantity)  
# Calculate correlation matrix 
correlation_matrix <- cor(numeric_data)  
# Visualize the correlation matrix 
ggcorr(numeric_data, label = TRUE)
```

The **`ggcorr()`** function is part of the **`GGally`** package in R, which extends **`ggplot2`** for easy creation of complex plots. **`GGally`** is particularly useful for visualizing relationships between multiple variables in a dataset.

The **`ggcorr()`** function is used to visualize a correlation matrix. It plots the correlation coefficients between variables, offering an intuitive graphical representation of how variables are related in terms of linear correlation.

The image shows a correlation matrix for the variables Sales, Profit, Discount, and Quantity. Here’s an interpretation of the correlation coefficients presented in the plot:

1.  **Sales**:
    -   **Profit**: There is a positive correlation of 0.5 between Sales and Profit. This indicates a moderate positive relationship, meaning as sales increase, profit tends to increase as well.
    -   **Discount**: The correlation between Sales and Discount is 0. This suggests no linear relationship between sales and discount.
    -   **Quantity**: There is a positive correlation of 0.2 between Sales and Quantity. This indicates a weak positive relationship, meaning as the quantity increases, sales also tend to increase slightly.
2.  **Profit**:
    -   **Discount**: There is a negative correlation of -0.2 between Profit and Discount. This indicates a weak negative relationship, meaning higher discounts are associated with slightly lower profits.
    -   **Quantity**: There is a positive correlation of 0.1 between Profit and Quantity. This indicates a very weak positive relationship, suggesting a slight tendency for profit to increase with quantity.
3.  **Discount**:
    -   **Quantity**: The correlation between Discount and Quantity is 0. This suggests no linear relationship between discount and quantity.

### Key Insights:

-   **Sales and Profit**: The moderate positive correlation (0.5) indicates that as sales increase, profit tends to increase as well, which is expected in most business scenarios.
-   **Profit and Discount**: The weak negative correlation (-0.2) suggests that increasing discounts slightly reduce profit, which makes sense because higher discounts reduce the revenue per sale.
-   **Sales and Quantity**: The weak positive correlation (0.2) indicates that selling more items tends to increase total sales, though the relationship is not very strong.

### Color Scale:

-   The color scale on the right indicates the strength and direction of the correlation:
    -   Red indicates positive correlations.
    -   Blue indicates negative correlations.
    -   The intensity of the color corresponds to the strength of the correlation, with darker colors indicating stronger correlations.

This correlation matrix helps to understand the relationships between key variables in your dataset and can guide further analysis or business decisions.

### 2. Regression Analysis: Linear Regression Example

**Introduction**: - Linear regression models the relationship between a dependent variable and one or more independent variables. You can use it to predict profit based on discount and quantity.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2)  

# Fit a linear regression model to predict Profit based on Discount and Quantity
regression_model <- lm(Profit ~ Discount + Quantity, data = superstore)  
# Summarize the regression model 

summary(regression_model)  

# Plot the regression results 
ggplot(superstore, aes(x = Discount, y = Profit)) +   
  geom_point() +   
  geom_smooth(method = "lm", se = FALSE) +   
  labs(title = "Linear Regression: Profit vs. Discount", x = "Discount", y = "Profit")
```

The results of the linear regression and the corresponding plot can be interpreted as follows:

### Regression Results:

1.  **Model Summary**:
    -   **Residuals**:
        -   The distribution of residuals provides insights into the model's fit. The range is from -6501.5 to 8323.6, indicating some outliers.
    -   **Coefficients**:
        -   **Intercept**:
            -   Estimate: 40.494
            -   Std. Error: 4.811
            -   t value: 8.417
            -   Pr(\>\|t\|): \< 2e-16 (highly significant)
        -   **Discount**:
            -   Estimate: -249.758
            -   Std. Error: 11.047
            -   t value: -22.608
            -   Pr(\>\|t\|): \< 2e-16 (highly significant)
        -   **Quantity**:
            -   Estimate: 7.174
            -   Std. Error: 1.025
            -   t value: 6.999
            -   Pr(\>\|t\|): 2.74e-12 (highly significant)
2.  **Significance Codes**:
    -   The significance codes indicate the level of significance for each predictor.
    -   Both Discount and Quantity are highly significant predictors of Profit (p-values \< 0.001).
3.  **Model Fit**:
    -   **Residual standard error**: 228 on 9993 degrees of freedom
    -   **Multiple R-squared**: 0.05283
    -   **Adjusted R-squared**: 0.05264
    -   **F-statistic**: 278.7 on 2 and 9993 DF
    -   **p-value**: \< 2.2e-16 (highly significant overall model)

### Interpretation:

1.  **Intercept**:
    -   The intercept of 40.494 suggests that when both Discount and Quantity are zero, the expected Profit is 40.494.
2.  **Discount**:
    -   The coefficient for Discount is -249.758. This indicates that for each unit increase in Discount, Profit decreases by approximately 249.758 units, holding Quantity constant. The negative coefficient and highly significant p-value suggest a strong inverse relationship between Discount and Profit.
3.  **Quantity**:
    -   The coefficient for Quantity is 7.174. This indicates that for each additional unit sold, Profit increases by approximately 7.174 units, holding Discount constant. The positive coefficient and highly significant p-value suggest a direct relationship between Quantity and Profit.
4.  **Model Fit**:
    -   The Multiple R-squared value of 0.05283 indicates that approximately 5.28% of the variability in Profit is explained by the model. This is relatively low, suggesting that there are other factors affecting Profit that are not included in the model.
    -   The F-statistic and its p-value indicate that the overall model is significant, meaning at least one of the predictors (Discount or Quantity) significantly contributes to the model.

### Plot Interpretation:

The plot of Profit vs. Discount with a linear regression line (using `geom_smooth()`) provides a visual representation of the relationship between Profit and Discount. The line appears almost flat, indicating that while the relationship is statistically significant, the effect size may not be large enough to be visually apparent.

### Conclusion:

The regression analysis shows that both Discount and Quantity are significant predictors of Profit. Discounts have a negative impact on Profit, while higher quantities sold have a positive impact. However, the model explains only a small portion of the variability in Profit, indicating that other factors also play a significant role in determining Profit.

### 3. Logistic Regression

**Introduction**: - Logistic regression models the probability of a binary outcome, such as whether an order was profitable (profit \> 0) based on predictors like discount, quantity, and ship mode.

**R Code**:

```{r}
# Load necessary libraries 

library(dplyr) 
library(ggplot2) 
library(broom)  

# Create a binary outcome for profitability 
superstore <- superstore %>%   mutate(Profitable = ifelse(Profit > 0, 1, 0))  

# Logistic Regression: Profitable by Discount, Quantity, and Ship Mode
logistic_model <- glm(Profitable ~ Discount + Quantity + `Ship Mode`, data = superstore, family = binomial) 

summary(logistic_model)  

# Extract and view model results 
tidy(logistic_model)
```

The results shown are from a logistic regression model (generalized linear model with a binomial family) predicting whether an order is profitable (`Profitable`) based on the discount applied (`Discount`), the quantity ordered (`Quantity`), and the shipping mode (`Ship Mode`). Here is the interpretation of the results:

### Coefficients:

1.  **Intercept**:
    -   **Estimate**: 6.08655
    -   **Std. Error**: 0.21508
    -   **z value**: 28.299
    -   **Pr(\>\|z\|)**: \< 2e-16 (highly significant)
    -   **Interpretation**: When Discount and Quantity are zero, and the shipping mode is the baseline category (presumably "First Class"), the log-odds of an order being profitable is 6.08655.
2.  **Discount**:
    -   **Estimate**: -22.81549
    -   **Std. Error**: 0.84425
    -   **z value**: -27.025
    -   **Pr(\>\|z\|)**: \< 2e-16 (highly significant)
    -   **Interpretation**: For each unit increase in Discount, the log-odds of an order being profitable decreases by 22.81549. This strong negative coefficient suggests that higher discounts significantly decrease the probability of an order being profitable.
3.  **Quantity**:
    -   **Estimate**: 0.03915
    -   **Std. Error**: 0.01920
    -   **z value**: 2.040
    -   **Pr(\>\|z\|)**: 0.0414 (significant at the 0.05 level)
    -   **Interpretation**: For each additional unit ordered, the log-odds of an order being profitable increases by 0.03915. This suggests that higher quantities slightly increase the probability of an order being profitable.
4.  **Ship Mode: Same Day**:
    -   **Estimate**: 0.02501
    -   **Std. Error**: 0.20646
    -   **z value**: 0.121
    -   **Pr(\>\|z\|)**: 0.9036 (not significant)
    -   **Interpretation**: The log-odds of an order being profitable for "Same Day" shipping mode compared to the baseline category is 0.02501. This effect is not statistically significant.
5.  **Ship Mode: Second Class**:
    -   **Estimate**: 0.12507
    -   **Std. Error**: 0.14437
    -   **z value**: 0.866
    -   **Pr(\>\|z\|)**: 0.3863 (not significant)
    -   **Interpretation**: The log-odds of an order being profitable for "Second Class" shipping mode compared to the baseline category is 0.12507. This effect is not statistically significant.
6.  **Ship Mode: Standard Class**:
    -   **Estimate**: -0.16989
    -   **Std. Error**: 0.11635
    -   **z value**: -1.460
    -   **Pr(\>\|z\|)**: 0.1442 (not significant)
    -   **Interpretation**: The log-odds of an order being profitable for "Standard Class" shipping mode compared to the baseline category is -0.16989. This effect is not statistically significant.

### Model Summary:

-   **Null Deviance**: 9826.3 on 9995 degrees of freedom
    -   This represents the fit of a model with only an intercept (no predictors).
-   **Residual Deviance**: 3919.1 on 9990 degrees of freedom
    -   This represents the fit of the model with all the predictors included. A lower value indicates a better fit.
-   **AIC (Akaike Information Criterion)**: 3931.1
    -   A lower AIC value indicates a better-fitting model.

### Interpretation:

1.  **Significant Predictors**:
    -   **Discount**: Highly significant with a strong negative impact on the probability of an order being profitable.
    -   **Quantity**: Significant with a small positive impact on the probability of an order being profitable.
2.  **Non-Significant Predictors**:
    -   **Ship Mode**: None of the shipping modes ("Same Day", "Second Class", "Standard Class") are statistically significant predictors of profitability compared to the baseline category.
3.  **Model Fit**:
    -   The significant reduction in deviance from the null model (9826.3) to the residual model (3919.1) suggests that the model with predictors fits the data significantly better than the null model.
    -   The number of Fisher Scoring iterations (8) indicates that the model converged successfully.

### Conclusion:

The logistic regression model indicates that Discount and Quantity are significant predictors of order profitability, with Discount having a strong negative impact and Quantity having a slight positive impact. The different shipping modes do not appear to have a significant effect on profitability. This information can help in making informed decisions about discount strategies and inventory management to optimize profitability.

### 4. Clustering: K-Means Clustering Example

**Introduction**: - K-means clustering partitions the data into k clusters, where each data point belongs to the cluster with the nearest mean. This can be used to group customers based on purchasing behavior.

**R Code**:

```{r}
# Load necessary libraries  
library(dplyr)  
library(ggplot2)   

# Select relevant columns and scale the data   
customer_data <- superstore %>% group_by(`Customer ID`) %>%  
  summarise(Total_Sales = sum(Sales), Total_Orders = n()) %>%   
  ungroup()    

scaled_data <- scale(customer_data %>% select(Total_Sales, Total_Orders))    

# Perform k-means clustering with 3 clusters  
set.seed(123) 
kmeans_result <- kmeans(scaled_data, centers = 3)    

# Add cluster assignment to the original data  
customer_data$Cluster <- as.factor(kmeans_result$cluster)    

# Visualize the clusters  
ggplot(customer_data, aes(x = Total_Sales, y = Total_Orders, color = Cluster)) +  
  geom_point() + 
  labs(title = "K-Means Clustering: Customers", x = "Total Sales", y = "Total Orders")
```

The plot displays the results of a K-Means clustering analysis on customers, segmented by `Total Sales` and `Total Orders`. Each customer is assigned to one of three clusters, represented by different colors: red, green, and blue.

### Interpretation:

1.  **Clusters**:
    -   **Cluster 1 (Red)**: Customers in this cluster tend to have higher total sales, with values ranging from approximately 5,000 to 25,000. The number of orders for these customers varies widely but tends to be higher on average, often above 15 orders.
    -   **Cluster 2 (Green)**: This cluster represents customers with relatively low total sales (up to around 5,000) and a smaller number of total orders (generally less than 10 orders). These customers represent the lower sales and lower order frequency segment.
    -   **Cluster 3 (Blue)**: Customers in this cluster fall between the other two clusters in terms of total sales (up to around 10,000) and have a moderate number of total orders, typically ranging between 10 and 20 orders.
2.  **Cluster Characteristics**:
    -   **Cluster 1**: High-value customers who make significant purchases (high total sales) and place many orders. These might be your most valuable customers in terms of revenue.
    -   **Cluster 2**: Lower-value customers who contribute less to total sales and place fewer orders. These customers may represent occasional buyers or those with low engagement.
    -   **Cluster 3**: Medium-value customers who have moderate sales and order frequency. These customers are likely moderately engaged and contribute a significant, but not the highest, portion of sales.
3.  **Business Implications**:
    -   **Targeting and Marketing**:
        -   **Cluster 1**: These high-value customers should be prioritized for loyalty programs, special offers, and personalized marketing to retain and further engage them.
        -   **Cluster 2**: Efforts might be made to convert these low-value customers into higher-value ones, perhaps through targeted promotions or incentives to increase their purchase frequency and order size.
        -   **Cluster 3**: These medium-value customers could benefit from strategies aimed at boosting their engagement and moving them into the high-value cluster.
4.  **Visualization Insights**:
    -   The clear separation between clusters suggests that the K-Means algorithm has effectively grouped customers based on their sales and ordering behavior.
    -   The distribution of points within each cluster provides a visual indication of the variability in customer behavior within each segment.

### Conclusion:

The K-Means clustering analysis has segmented customers into three distinct groups based on their total sales and total orders. Each cluster represents a different level of customer value and engagement, providing insights that can guide targeted marketing strategies, customer relationship management, and business decision-making to optimize sales and customer satisfaction.

### 5. Principal Component Analysis (PCA)

**Introduction**: - Principal Component Analysis (PCA) reduces the dimensionality of our dataset while preserving as much variability as possible, which can help in visualizing high-dimensional data.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(FactoMineR)
library(factoextra)  

# Select numeric columns for PCA 
numeric_data <- superstore %>%  select(Sales, Profit, Discount, Quantity)  

# Perform PCA 
pca_result <- PCA(numeric_data, graph = FALSE)  

# Visualize PCA 
fviz_pca_var(pca_result, col.var = "contrib", gradient.cols = c("blue", "red"))
```

The image displays the results of a Principal Component Analysis (PCA) on selected numeric columns (`Sales`, `Profit`, `Discount`, `Quantity`) from the dataset.

Here is the interpretation of the PCA plot:

### Interpretation of the PCA Plot:

1.  **Principal Components (Dimensions)**:
    -   **Dim1 (PC1)**: The first principal component, which explains 39.7% of the variance in the data.
    -   **Dim2 (PC2)**: The second principal component, which explains 26.5% of the variance in the data.
    -   Together, these two components explain a significant portion (66.2%) of the total variance in the data, indicating that PCA has effectively reduced the dimensionality while retaining most of the variability.
2.  **Variable Contributions**:
    -   **Sales** and **Profit** have strong positive loadings on Dim1, suggesting that they are positively correlated and contribute similarly to this principal component.
    -   **Discount** has a strong negative loading on Dim1, indicating that it is inversely related to Sales and Profit.
    -   **Quantity** has a positive loading on Dim2, suggesting it is primarily explained by this second component.
3.  **Correlation and Relationships**:
    -   The length and direction of the arrows represent the strength and direction of the correlation between the variables and the principal components.
    -   **Sales** and **Profit** arrows point in the same direction, indicating a strong positive correlation.
    -   **Discount** points in the opposite direction to **Sales** and **Profit**, indicating an inverse relationship with these variables.
    -   **Quantity** points in a different direction, indicating it has a distinct contribution to the variance explained by Dim2.
4.  **Color Gradient (Contribution)**:
    -   The color gradient from blue to red indicates the contribution of each variable to the principal components. Variables with darker red arrows contribute more to the principal components.

### Insights from the PCA:

1.  **Dimension 1 (Dim1)**:
    -   Captures the trade-off between high Sales and Profit versus high Discounts.
    -   A high score on Dim1 indicates higher Sales and Profit and lower Discount, while a low score indicates the opposite.
2.  **Dimension 2 (Dim2)**:
    -   Captures the variance primarily explained by Quantity.
    -   A high score on Dim2 indicates higher Quantity.

### Practical Implications:

1.  **Sales and Profit**:
    -   These two variables are strongly positively correlated, meaning that as sales increase, profits also increase, which is expected in most business contexts.
2.  **Discount**:
    -   There is a strong inverse relationship between Discount and both Sales and Profit, suggesting that higher discounts might be associated with lower sales and profit.
3.  **Quantity**:
    -   Quantity has a different pattern compared to the other variables, indicating it captures a unique aspect of the data variability.

### Conclusion:

The PCA plot provides a clear visualization of the relationships between Sales, Profit, Discount, and Quantity.

It shows that Sales and Profit are positively correlated and both inversely related to Discount.

Quantity contributes to the second dimension, indicating its unique contribution to the overall variance.

This analysis helps in understanding the underlying structure of the data and can guide further decision-making and strategic planning.

### 6. Hierarchical Clustering

**Introduction**: - Hierarchical clustering creates a hierarchy of clusters, which can help identify similar groups within your data, such as states or cities based on sales and profit.

**R Code**:

```{r}

# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(cluster) 
library(factoextra)  

# Aggregate data by state 
state_data <- superstore %>%   group_by(State) %>% summarise(Total_Sales = sum(Sales), Total_Profit = sum(Profit))  

# Scale the data 
scaled_data <- scale(state_data %>% select(Total_Sales, Total_Profit))  

# Perform hierarchical clustering 
hc <- hclust(dist(scaled_data))  

# Visualize the dendrogram 
fviz_dend(hc, k = 4, rect = TRUE, show_labels = TRUE)
```

The image shows the results of hierarchical clustering on state-level data based on total sales and total profit. Here is the interpretation of the dendrogram:

### Interpretation of the Dendrogram:

1.  **Dendrogram Structure**:
    -   The dendrogram represents the hierarchy of clusters formed by the hierarchical clustering algorithm.
    -   The height at which two clusters are joined indicates the dissimilarity (or distance) between them. Higher joins represent more dissimilar clusters.
2.  **Clusters**:
    -   The dendrogram shows four clusters, as indicated by the colored rectangles and the `k = 4` parameter in the `fviz_dend` function.
    -   The colors represent different clusters. Each cluster groups states that are similar in terms of their total sales and total profit.
3.  **Cluster Heights**:
    -   The y-axis (height) represents the distance or dissimilarity between clusters.
    -   Taller heights indicate greater dissimilarity between the clusters being joined.
    -   Shorter heights indicate that the clusters are more similar to each other.
4.  **Cluster Characteristics**:
    -   **Cluster 1 (Red)**: Contains states with relatively high dissimilarity compared to other states.
    -   **Cluster 2 (Green)**: Groups states with moderate sales and profit.
    -   **Cluster 3 (Blue)**: Contains the majority of states, indicating that these states have similar sales and profit characteristics.
    -   **Cluster 4 (Purple)**: Groups states with specific similar characteristics, likely outliers or unique patterns in sales and profit.

### Practical Implications:

1.  **Identifying Similar States**:
    -   The clustering helps identify groups of states that have similar sales and profit patterns.
    -   This can be useful for regional marketing strategies, sales forecasting, and resource allocation.
2.  **Understanding Outliers**:
    -   States in Cluster 1 (Red) and Cluster 4 (Purple) may be outliers or have unique sales and profit characteristics.
    -   These states might require special attention or tailored strategies.
3.  **Resource Allocation**:
    -   By understanding which states belong to which clusters, businesses can allocate resources more efficiently.
    -   For example, states in Cluster 3 (Blue) might benefit from a uniform marketing strategy, while states in Cluster 1 (Red) might need a customized approach.

### Conclusion:

The hierarchical clustering analysis provides a clear visualization of how states are grouped based on their sales and profit.

The dendrogram reveals four distinct clusters, indicating different patterns of sales and profit among the states.

This analysis can guide strategic decisions in marketing, sales, and resource allocation to optimize performance across different regions.

### 7. Time Series Decomposition

**Introduction**: - Time series decomposition separates a time series into trend, seasonal, and residual components, which helps understand underlying patterns in the data.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(forecast)  

# Ensure the 'Order Date' column is in Date format
superstore <- superstore %>%
  mutate(`Order Date` = as.Date(`Order Date`, format = "%m/%d/%Y"))  # Adjust the format as needed

# Aggregate sales data by month 
monthly_sales <- superstore %>% 
  group_by(Month = format(`Order Date`, "%Y-%m")) %>%   
  summarise(Total_Sales = sum(Sales))  

# Convert to time series object 
sales_ts <- ts(monthly_sales$Total_Sales, start = c(2014, 1), frequency = 12)  

# Decompose time series 
decomposed <- decompose(sales_ts)  

# Plot decomposition 
autoplot(decomposed)
```

The image shows the results of a time series decomposition of total sales, separating the time series into trend, seasonal, and residual components. Here is the interpretation of each component shown in the decomposition plot:

### Interpretation of the Decomposition Plot:

1.  **Data**:
    -   The top panel shows the original time series data for total sales from 2014 to 2018.
    -   This represents the raw data with all its variability, including trends, seasonality, and random noise.
2.  **Trend**:
    -   The second panel shows the trend component, which captures the long-term movement in the data.
    -   The trend indicates that total sales have been generally increasing over the period, with some fluctuations.
    -   The increase is more noticeable starting around mid-2015 and continues upwards towards the end of 2017.
3.  **Seasonal**:
    -   The third panel shows the seasonal component, which captures the repeating patterns or cycles within a year.
    -   There are clear seasonal fluctuations in sales, with peaks and troughs repeating annually.
    -   The seasonality indicates that sales tend to be higher at certain times of the year and lower at others, following a consistent pattern each year.
4.  **Remainder (Residual)**:
    -   The bottom panel shows the remainder component, which captures the irregular fluctuations after removing the trend and seasonal components.
    -   These are the random noise or unexpected variations in the data.
    -   The residuals should ideally have no clear pattern and be randomly distributed around zero.

### Practical Implications:

1.  **Understanding Trends**:
    -   The upward trend indicates that total sales have been increasing over the analyzed period. This positive trend is a good sign for business growth.
2.  **Seasonal Patterns**:
    -   The presence of clear seasonal patterns suggests that certain times of the year consistently experience higher or lower sales.
    -   Understanding these patterns can help in planning inventory, marketing campaigns, and resource allocation to maximize sales during peak periods and manage lower sales periods effectively.
3.  **Managing Irregular Variations**:
    -   By isolating the residual component, businesses can identify unusual fluctuations that are not explained by the trend or seasonal patterns.
    -   Analyzing these residuals can help in identifying specific events or anomalies that impact sales, allowing for more targeted interventions.

### Conclusion:

The time series decomposition provides valuable insights into the underlying patterns in the total sales data.

The increasing trend indicates overall growth, while the seasonal component reveals regular fluctuations throughout the year.

The residual component highlights the random noise, helping to isolate and understand irregular variations.

These insights can guide strategic planning, resource allocation, and marketing efforts to optimize sales performance.

### 8. Cox Proportional Hazards Model

**Introduction**: - The Cox Proportional Hazards Model is used to model the time until an event occurs, such as the time until a customer makes a repeat purchase.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(survival) 
library(ggplot2) 
library(survminer)  

# Assume we have a customer data frame with columns: Customer_ID, Order_Date, and Repeat_Purchase (1 if repeat, 0 if not) 

# Create a sequence of dates from January 2014 to December 2017
order_dates <- seq(as.Date("2014-01-01"), as.Date("2017-12-31"), by = "month")

# Repeat this sequence to ensure we have 1000 dates
order_dates <- rep(order_dates, length.out = 1000)

# Create the customer data
set.seed(123)
customer_data <- data.frame(
  Customer_ID = rep(1:100, each = 10),
  Order_Date = order_dates,
  Repeat_Purchase = sample(0:1, 1000, replace = TRUE)
)

# Create a survival object 
surv_object <- Surv(time = as.numeric(customer_data$Order_Date), event = customer_data$Repeat_Purchase)  

# Fit Cox proportional hazards model 
cox_model <- coxph(surv_object ~ Customer_ID, data = customer_data) 
summary(cox_model)  
```

### Interpretation of the Cox Proportional Hazards Model Results

The output shows the results of a Cox proportional hazards model applied to the customer data, which includes the `Customer_ID`, `Order_Date`, and `Repeat_Purchase` variables. Here is a detailed interpretation of the results:

#### Cox Model Summary:

The Cox proportional hazards model is used to evaluate the effect of customer ID on the likelihood of repeat purchases over time.

**Model Fit:** - The model was fit with 1000 observations and 494 events (repeat purchases).

**Coefficient (coef):** - `Customer_ID`: The coefficient for `Customer_ID` is -2.119e-05, which is very close to zero. This suggests that there is no substantial effect of customer ID on the hazard (risk) of repeat purchases.

**Exponentiated Coefficient (exp(coef)):** - `exp(coef)` for `Customer_ID` is 1.000e+00, which equals 1. This means that the hazard ratio for customer ID is 1, indicating no change in hazard with changes in customer ID.

**Standard Error (se(coef)):** - The standard error for `Customer_ID` is 1.580e-03, which is relatively small but given the coefficient is near zero, the effect is still insignificant.

**Wald Test Statistic (z):** - The z-value for `Customer_ID` is -0.013, which is close to zero. This indicates that the effect of customer ID on the hazard is not statistically significant.

**P-value (Pr(\>\|z\|)):** - The p-value for `Customer_ID` is 0.989, which is much greater than the common significance level (e.g., 0.05). This means we fail to reject the null hypothesis that the coefficient is zero, indicating no significant effect of customer ID on repeat purchase.

**Confidence Intervals:** - The 95% confidence interval for `exp(coef)` ranges from 0.9969 to 1.003. Since this interval includes 1, it further indicates that the effect of customer ID on the hazard is not statistically significant.

**Model Statistics:** - **Concordance:** 0.503 (se = 0.015): The concordance index measures the predictive accuracy of the model. A value of 0.503 suggests that the model has about a 50.3% chance of correctly ranking pairs of observations by their risk, which is slightly better than random chance (0.5). - **Likelihood ratio test:** 0 on 1 df, p=1: This test assesses the overall significance of the model. A p-value of 1 indicates that the model is not significantly better than a null model (with no predictors). - **Wald test:** 0 on 1 df, p=1: This test assesses the significance of the individual predictors. A p-value of 1 again indicates no significant effect. - **Score (logrank) test:** 0 on 1 df, p=1: This test is another method to assess the overall significance of the model, with the same conclusion that the model is not significant.

#### Practical Implications:

**No Significant Effect of Customer ID:** - The analysis indicates that customer ID does not have a significant effect on the likelihood of repeat purchases. This suggests that other factors, not included in the model, might be driving repeat purchases.

**Model Performance:** - The model's concordance index is close to 0.5, indicating it does not perform much better than random chance in predicting repeat purchases.

**Strategic Decisions:** - Since customer ID is not a significant predictor of repeat purchases, it might be beneficial to explore other variables such as purchase frequency, product categories, customer demographics, or engagement metrics to better understand and predict repeat purchase behavior.

**Future Analysis:** - Additional data and more complex models (including interaction terms or non-linear effects) might be necessary to capture the factors influencing repeat purchases.

**Conclusion:** - The current Cox proportional hazards model does not find a significant relationship between customer ID and repeat purchase behavior. Future analyses should consider other potential predictors to improve the understanding and prediction of repeat purchases.

**The Cox Proportional Hazards Model vs The Exponential Distribution**

The Cox Proportional Hazards Model and the exponential distribution are both used to model time-to-event data, but they serve different purposes and have different properties. Here's a comparison to clarify their similarities and differences:

### Cox Proportional Hazards Model

-   **Purpose:** The Cox Proportional Hazards Model is used to investigate the relationship between the time until an event occurs (such as time until a customer makes a repeat purchase) and one or more predictor variables (covariates).
-   **Model Form:** It is a semi-parametric model, meaning it makes no assumptions about the baseline hazard function (which can vary over time), but it assumes that the effect of the covariates on the hazard is multiplicative and constant over time.
-   **Hazard Function:** The model estimates hazard ratios, which describe the effect of covariates on the hazard of the event occurring.
-   **Flexibility:** The Cox model can handle time-varying covariates and allows for the inclusion of multiple covariates to adjust for confounding factors.
-   **Interpretation:** It provides hazard ratios for each covariate, indicating the relative risk of the event occurring for different values of the covariate.

### Exponential Distribution

-   **Purpose:** The exponential distribution is a continuous probability distribution used to model the time between events in a Poisson process, where events occur continuously and independently at a constant average rate.
-   **Model Form:** It is a parametric model with a single parameter (the rate parameter, λ), which is the inverse of the mean time between events.
-   **Hazard Function:** The hazard function for the exponential distribution is constant over time (λ). This implies that the event rate is the same at all times, which is a strong assumption.
-   **Flexibility:** It is less flexible than the Cox model because it assumes a constant hazard rate over time.
-   **Interpretation:** The rate parameter, λ, indicates the average rate at which events occur, and the mean time between events is 1/λ.

### Key Differences

-   **Assumptions:** The Cox model does not assume a specific form for the baseline hazard function, while the exponential distribution assumes a constant hazard rate.
-   **Flexibility:** The Cox model can handle multiple covariates and their effects on the hazard, whereas the exponential distribution is typically used for simpler models with a constant event rate.
-   **Applications:** The Cox model is widely used in survival analysis and epidemiology to assess the impact of covariates on survival times. The exponential distribution is often used in reliability engineering and queuing theory to model the time between failures or arrivals.

### Example Comparison

**Cox Proportional Hazards Model Example:**

``` r
# Fit Cox proportional hazards model
cox_model <- coxph(Surv(time, status) ~ age + sex, data = lung)
summary(cox_model)
```

**Exponential Distribution Example:**

``` r
# Fit exponential distribution to time-to-event data
time_to_event <- rexp(100, rate = 0.1)
hist(time_to_event, breaks = 20, main = "Histogram of Exponential Data", xlab = "Time to Event")
```

In summary, while both the Cox Proportional Hazards Model and the exponential distribution are used for modeling time-to-event data, the Cox model is more flexible and robust for handling complex relationships with multiple covariates, whereas the exponential distribution is simpler and assumes a constant hazard rate over time.

### 9. Survival Analysis

**Introduction**: - Survival analysis estimates the expected duration of time until one or more events occur, such as customer churn.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(survival) 
library(ggplot2) 
library(survminer)  
  
# Assume we have a customer data frame with columns: Customer_ID, Order_Date, and Churn (1 if churn, 0 if not)
  
# Create a sequence of dates from January 2014 to December 2017
order_dates <- seq(as.Date("2014-01-01"), as.Date("2017-12-31"), by = "month")
  
# Repeat this sequence to ensure we have 1000 dates
order_dates <- rep(order_dates, length.out = 1000)
  
# Create a dummy dataset for illustration purposes 
customer_data <- data.frame(Customer_ID = rep(1:100, each = 10),   Order_Date = order_dates, Churn = sample(0:1, 1000, replace = TRUE) )  
  
# Create a survival object 
surv_object <- Surv(time = as.numeric(customer_data$Order_Date), event = customer_data$Churn)  
  
# Fit Kaplan-Meier survival curve 
km_fit <- survfit(surv_object ~ 1, data = customer_data)  
  
# Plot the survival curve 
ggsurvplot(km_fit, data = customer_data, xlab = "Days", ylab = "Survival Probability", title = "Kaplan-Meier Survival Curve")
```

### Interpretation of the Kaplan-Meier Survival Curve

The Kaplan-Meier survival curve shown in the plot represents the survival probability over time, where "survival" in this context refers to the probability that a customer has not churned by a given time.

#### Kaplan-Meier Survival Curve:

**Plot Description:** - **X-axis (Days):** The number of days since the beginning of the observation period. - **Y-axis (Survival Probability):** The probability that a customer has not churned (remains a customer) at a given time. - **Curve:** The survival curve shows the estimated survival probability over time. The curve starts at 1 (or 100%) and decreases as customers churn over time. - **Strata Legend:** Indicates that all customers are considered together without stratification.

**Key Observations:** 1. **Initial Survival Probability:** - At the start (time = 0), the survival probability is 1, meaning all customers are active.

2.  **Survival over Time:**
    -   The curve remains flat at 1 for a significant portion of the time, indicating that customers did not churn during this period.
    -   Towards the end of the observation period (around 15,000 days), the curve starts to decline, indicating an increase in churn events.
3.  **Final Survival Probability:**
    -   The survival probability drops sharply at the end, reflecting a higher rate of churn as the time progresses towards the end of the observation period.
    -   This sharp decline might be due to the data structure, suggesting that many customers are recorded as having churned towards the end of the observation period.

**Interpretation:** - **Low Churn in Initial and Middle Periods:** The flat survival curve for most of the observation period suggests that customers tend to stay with the company for a long duration without churning. - **Increased Churn at the End:** The sharp decline towards the end indicates a significant increase in churn events, possibly due to the duration of the study or a specific time-related factor affecting customer retention. - **Overall Survival Probability:** The general shape of the curve suggests that the majority of the customers remain with the company until the end of the observation period.

**Practical Implications:** - **Retention Strategies:** Given the low churn in the initial and middle periods, efforts to retain customers should focus on understanding and mitigating the factors that lead to the increased churn towards the end. - **Further Analysis:** Investigate why churn rates increase towards the end of the observation period. This could involve looking at customer feedback, changes in service, market conditions, or other external factors. - **Targeted Interventions:** Develop targeted interventions for customers who are approaching the end of the observation period to prevent churn, based on the identified factors.

### Conclusion

The Kaplan-Meier survival curve provides a visual representation of customer retention over time, showing a high retention rate initially and a significant increase in churn towards the end. This information can be used to guide strategies aimed at improving customer retention and understanding the factors driving churn.
