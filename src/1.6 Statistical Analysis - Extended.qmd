---
title: "1.x Statistical Analysis - Extended"
format: html
editor: visual
include-before: |
  <div style="text-align: center;">
    <img src="images/department_logo.png" width="169" />
    <img src="images/ioa_logo.png" width="122" />
    <img src="images/petra_logo.png" width="52" />
  </div>
---

### Summary of Hypthesis Tests

Here's a table summarizing the parametric tests and their non-parametric counterparts, including any missing important tests:

| Parametric Test                  | Use                                                            | Assumptions                                                       | Interpretation                                                           | Non-Parametric Counterpart                   | Use                                                                            | Assumptions                                           | Interpretation                                                              |
|---------|---------|---------|---------|---------|---------|---------|---------|
| One-sample T-test                | Test if the mean of a single sample differs from a known mean. | Normality, independence                                           | p-value \< 0.05 indicates significant difference from the known mean.    | One-sample Wilcoxon Signed-Rank Test         | Test if the median of a single sample differs from a known median.             | Symmetric distribution, independence                  | p-value \< 0.05 indicates significant difference from the known median.     |
| Two-sample T-test (Independent)  | Compare the means of two independent samples.                  | Independence, normality, equal variances                          | p-value \< 0.05 indicates significant difference between means.          | Mann-Whitney U Test (Wilcoxon Rank-Sum Test) | Compare distributions of two independent samples.                              | Independence, ordinal/continuous data, similar shapes | p-value \< 0.05 indicates significant difference in distributions.          |
| Paired Sample T-test             | Compare means of two related samples.                          | Normality of differences, independence of pairs                   | p-value \< 0.05 indicates significant difference between paired samples. | Wilcoxon Signed-Rank Test                    | Compare distributions of two related samples.                                  | Symmetric differences, independence of pairs          | p-value \< 0.05 indicates significant difference in distributions.          |
| One-way ANOVA                    | Compare means of three or more groups.                         | Normality, homogeneity of variances, independence                 | p-value \< 0.05 indicates significant difference among group means.      | Kruskal-Wallis Test                          | Compare distributions of three or more independent groups.                     | Independence, ordinal/continuous data, similar shapes | p-value \< 0.05 indicates significant difference among group distributions. |
| Chi-square Test for Independence | Test for association between two categorical variables.        | Count data, independence, expected frequencies ≥ 5                | p-value \< 0.05 indicates significant association.                       | Fisher's Exact Test                          | Test for association between two categorical variables (small sample sizes).   | Count data, independence, small sample sizes          | p-value \< 0.05 indicates significant association.                          |
| Pearson Correlation              | Measure linear relationship between two continuous variables.  | Normality, linearity, homoscedasticity                            | p-value \< 0.05 indicates significant correlation.                       | Spearman's Rank Correlation                  | Measure monotonic relationship between two continuous/ordinal variables.       | Ordinal/continuous data, monotonic relationship       | p-value \< 0.05 indicates significant correlation.                          |
| Two-way ANOVA                    | Compare means of groups split on two factors.                  | Normality, homogeneity of variances, independence                 | p-value \< 0.05 indicates significant interaction or main effects.       | Friedman Test                                | Compare distributions of groups split on two factors.                          | Ordinal data, independence, blocks                    | p-value \< 0.05 indicates significant interaction or main effects.          |
| Linear Regression                | Predict a continuous outcome based on one or more predictors.  | Linearity, independence, homoscedasticity, normality of residuals | p-value \< 0.05 indicates significant predictors.                        | Non-parametric Regression (e.g., LOESS)      | Predict a continuous outcome without assuming a specific form of relationship. | Assumptions vary based on method used                 | p-value \< 0.05 indicates significant predictors or relationships.          |

## Practical Examples and Exercises

### 1. One-sample T-test

**Use:** To test if the mean of a single sample is significantly different from a known or hypothesized population mean.

**Assumptions:**

\- The sample data is normally distributed.

\- The sample observations are independent.

***Example:- Suppose we want to test if the average satisfaction score of customers for a new product is significantly different from the target satisfaction score of 5.***

**Experiment Design**

Conducting an experiment to test if the average satisfaction score of customers for a new product is significantly different from a target satisfaction score of 5 involves several scientific steps. Here’s a structured approach:

**Step 1: Define the Hypothesis**

-   **Null Hypothesis ((H_0))**: The mean satisfaction score is equal to 5.
-   **Alternative Hypothesis ((H_1))**: The mean satisfaction score is not equal to 5.

**Step 2: Design the Experiment**

1.  **Sample Size Determination**: Determine the appropriate sample size to ensure the results are statistically significant. This can be done using power analysis, considering the expected effect size, significance level (alpha), and power (1 - beta).

2.  **Random Sampling**: Select a random sample of customers to avoid bias. Ensure the sample is representative of the population.

3.  **Survey Design**: Create a standardized survey to measure customer satisfaction. Use a reliable and validated scale (e.g., Likert scale from 1 to 7).

4.  **Data Collection**: Administer the survey to the selected sample of customers after they have used the new product for a sufficient period.

**Step 3: Conduct the Experiment**

1.  **Administer the Survey**: Ensure that the data collection process is uniform and unbiased. Use online surveys, interviews, or physical questionnaires as appropriate.

2.  **Collect Data**: Gather the responses, ensuring data integrity and confidentiality.

**Step 4: Analyze the Data**

1.  **Descriptive Statistics**: Calculate the mean, median, standard deviation, and other relevant statistics of the collected data.

2.  **Check Assumptions**: Ensure the data meets the assumptions for a t-test (e.g., normally distributed data, independent samples).

3.  **Conduct the t-test**: Use statistical software (e.g., R) to perform a one-sample t-test to compare the sample mean to the target satisfaction score of 5.

**Step 5: Interpret the Results**

1.  **P-value and Test Statistic**: Evaluate the t-test result, focusing on the t-statistic and p-value.
    -   If the p-value is less than the significance level (usually 0.05), reject the null hypothesis.
    -   If the p-value is greater than the significance level, do not reject the null hypothesis.
2.  **Confidence Interval**: Examine the 95% confidence interval for the mean satisfaction score to understand the range in which the true mean lies.

**Step 6: Report the Findings**

1.  **Document the Process**: Describe the methodology, sample size, data collection process, and statistical analysis in detail.

2.  **Present the Results**: Use tables, graphs, and descriptive text to present the findings clearly. Highlight whether the average satisfaction score is significantly different from 5.

3.  **Draw Conclusions**: Summarize the findings and discuss the implications. If the null hypothesis is rejected, discuss potential reasons and next steps.

**Example Analysis in R**

Here’s an example of how to perform the t-test in R:

``` r
# Set seed for reproducibility
set.seed(123)

# Generate customer satisfaction scores (replace this with actual survey data)
satisfaction_scores <- rnorm(30, mean = 5, sd = 2)

# Perform one-sample t-test
t_test_result <- t.test(satisfaction_scores, mu = 5)

# Print the t-test result
print(t_test_result)

# Calculate the critical value for the t-distribution
alpha <- 0.05
df <- length(satisfaction_scores) - 1
critical_value <- qt(1 - alpha/2, df)

# Print the critical value
cat("Critical value for a two-tailed test with alpha =", alpha, "and df =", df, "is", critical_value, "\n")
```

**Reporting the Example Analysis**

-   **T-test Result**: The t-statistic is (-0.26299) with a p-value of (0.7944).
-   **Critical Value**: The critical value for a two-tailed test with alpha (0.05) and (29) degrees of freedom is approximately (2.045).
-   **Conclusion**: Since the p-value is greater than (0.05), we do not reject the null hypothesis. There is not enough evidence to conclude that the mean satisfaction score is significantly different from (5).

By following these steps, you can ensure that your experiment is conducted in a scientific manner, producing reliable and valid results.

**Code:**

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate customer satisfaction scores
satisfaction_scores <- rnorm(30, mean = 5, sd = 2)

# Print the satisfaction scores
print(satisfaction_scores)

# Perform one-sample t-test to test if the mean satisfaction score is significantly different from 5
t_test_result <- t.test(satisfaction_scores, mu = 5)

# Print the t-test result
print(t_test_result)
```

**Interpretation:**

**Satisfaction Scores:** Generated customer satisfaction scores with a mean of approximately 5.

-   **T-test Result:**

    -   **t:** Test statistic (-0.26299)

    -   **df:** Degrees of freedom (29)

    -   **p-value:** Probability of observing the data if the null hypothesis is true (0.7944)

    -   **95% Confidence Interval:** Range within which the true mean lies with 95% confidence (4.173147 to 5.638438)

    -   **Sample Mean (mean of x):** Average satisfaction score (4.905792)

**Conclusion:** Since the p-value (0.7944) is greater than the common significance level (0.05), we fail to reject the null hypothesis.

This indicates that the average satisfaction score is not significantly different from the target score of 5.

### 2. Two-sample T-test (Independent)

**Use:** To compare the means of two independent samples to see if they are significantly different.

**Assumptions:**

\- The samples are independent of each other.

\- The data in each sample is normally distributed.

\- The variances of the two populations are equal (if using the standard t-test, not Welch's).

***Example:- Suppose we want to test if there is a significant difference in average performance scores between employees who received training and those who did not.***

**Code:**

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate performance scores for two groups
trained_employees <- rnorm(30, mean = 75, sd = 10)  # Employees who received training
untrained_employees <- rnorm(30, mean = 70, sd = 10)  # Employees who did not receive training

# Perform two-sample t-test to compare the mean performance scores between trained and untrained employees
t_test_result <- t.test(trained_employees, untrained_employees)

# Print the performance scores
print(trained_employees)
print(untrained_employees)

# Print the t-test result
print(t_test_result)
```

**Interpretation:**

-   **Performance Scores:**

    -   **Trained Employees:** Generated performance scores with a mean of approximately 75.

    -   **Untrained Employees:** Generated performance scores with a mean of approximately 70.

-   **T-test Result:**

    -   **t:** Test statistic (1.672)

    -   **df:** Degrees of freedom (56.559)

    -   **p-value:** Probability of observing the data if the null hypothesis is true (0.248)

    -   **95% Confidence Interval:** Range within which the true mean difference lies with 95% confidence (-1.965426 to 7.456584)

    -   **Sample Means (mean of x, mean of y):** Average performance scores for trained employees (74.52896) and untrained employees (71.78338)

**Conclusion:** Since the p-value (0.1104) is greater than the common significance level (0.05), we fail to reject the null hypothesis.

This indicates that there is no significant difference in average performance scores between trained and untrained employees

Note: althought the averages are quite difference, yet, the t-test showed that there is not significant difference. Here is the interpretation for that:

The two-sample t-test takes into account not only the difference in means but also the variability within each group and the sample size. Here are some possible reasons why the t-test might not find a significant difference even if the means appear different:

1.  **Variability within Groups:** If the variability (standard deviation) within each group is high, it can obscure the difference between the group means.
2.  **Sample Size:** Smaller sample sizes result in less precise estimates of the mean, making it harder to detect a significant difference.
3.  **p-value and Significance Level:** The p-value might not be less than the significance level (usually 0.05), indicating that the observed difference could be due to random chance.

Let’s take a closer look at the standard deviations and sample sizes in your example. We will also plot the data to visualize the distributions.

### Revised Example: Two-sample T-test with Additional Insights

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate performance scores for two groups
trained_employees <- rnorm(30, mean = 75, sd = 10)  # Employees who received training
untrained_employees <- rnorm(30, mean = 70, sd = 10)  # Employees who did not receive training

# Print summary statistics
summary(trained_employees)
summary(untrained_employees)

# Calculate standard deviations
sd(trained_employees)
sd(untrained_employees)

# Perform two-sample t-test to compare the mean performance scores between trained and untrained employees
t_test_result <- t.test(trained_employees, untrained_employees)

# Print the t-test result
print(t_test_result)

# Plot the data
library(ggplot2)
data <- data.frame(
  score = c(trained_employees, untrained_employees),
  group = factor(rep(c("Trained", "Untrained"), each = 30))
)

ggplot(data, aes(x = group, y = score)) +
  geom_boxplot() +
  geom_jitter(width = 0.2) +
  labs(title = "Performance Scores by Training Status", x = "Group", y = "Performance Score")
```

**Summary Statistics and Standard Deviations:**

```{r}
# Summary statistics
summary(trained_employees)
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# 52.27   66.75   74.71   75.10   82.31   96.20 

summary(untrained_employees)
# Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
# 55.30   65.04   73.78   70.16   77.65   83.63 

# Standard deviations
sd(trained_employees)
# [1] 10.34925

sd(untrained_employees)
# [1] 9.403503
```

### Interpretation:

-   **Performance Scores:**
    -   **Trained Employees:** Mean = 75.10, SD = 10.35
    -   **Untrained Employees:** Mean = 70.16, SD = 9.40
-   **T-test Result:**
    -   **t:** Test statistic (1.6201)
    -   **df:** Degrees of freedom (57.635)
    -   **p-value:** Probability of observing the data if the null hypothesis is true (0.1104)
    -   **95% Confidence Interval:** Range within which the true mean difference lies with 95% confidence (-1.084326 to 9.984326)

**Conclusion:** Although the means appear different, the standard deviations are relatively high (10.35 and 9.40), which means there is substantial variability within each group. The p-value (0.1104) indicates that the observed difference could be due to random chance, and it is not statistically significant at the 0.05 level.

The boxplot visualization also helps to see the overlap in the distributions of the scores between the two groups, reinforcing the result that the difference is not statistically significant.

This revised example shows how variability and sample size can impact the results of a t-test, and why it's essential to consider these factors when interpreting the results.

### 3. Paired Sample T-test

**Use:** To compare the means of two related samples (e.g., before and after measurements on the same subjects).

**Assumptions:** - The differences between the paired observations are normally distributed. - The pairs are independent of each other.

**Example:**- Suppose we want to test if a training program has significantly improved employee productivity scores by comparing their productivity before and after the training.

**Code:**

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate productivity scores before and after the training
productivity_before <- rnorm(30, mean = 5, sd = 2)  # Productivity scores before training
productivity_after <- productivity_before + rnorm(30, mean = 0.5, sd = 1)  # Productivity scores after training

# Perform paired sample t-test to compare the mean productivity scores before and after training
t_test_result <- t.test(productivity_before, productivity_after, paired = TRUE)

# Print the productivity scores
print(productivity_before)
print(productivity_after)

# Print the t-test result
print(t_test_result)
```

**Interpretation:**

-   **Productivity Scores:**

    -   **Before Training:** Generated productivity scores with a mean of approximately 5.

    -   **After Training:** Generated productivity scores that are on average higher than before training.

-   **T-test Result:**

    -   **t:** Test statistic (-4.4489)

    -   **df:** Degrees of freedom (29)

    -   **p-value:** Probability of observing the data if the null hypothesis is true (0.0001169)

    -   **95% Confidence Interval:** Range within which the true mean difference lies with 95% confidence (-0.9901802 to -0.3664964=)

    -   **Mean of the Differences:** Average difference in productivity scores before and after training (-0.6783383)

**Conclusion:** Since the p-value (0.0001169) is less than the common significance level (0.05), we reject the null hypothesis.

This indicates that there is a significant difference in productivity scores before and after the training, with productivity increasing after the training program.

### 4. One-way ANOVA

**Use:** To compare the means of three or more groups to see if at least one mean is different.

**Assumptions:** - The data in each group is normally distributed. - The variances of the populations are equal (homogeneity of variances). - The samples are independent.

**Example:**- Suppose we want to test if there is a significant difference in customer satisfaction scores among three different service plans (Basic, Standard, Premium).

**Code:**

```{r}
# Load necessary library
library(dplyr)

# Set seed for reproducibility
set.seed(123)

# Generate satisfaction scores for three different service plans
basic_plan <- rnorm(30, mean = 5, sd = 2)  # Basic Plan
standard_plan <- rnorm(30, mean = 6, sd = 2)  # Standard Plan
premium_plan <- rnorm(30, mean = 7, sd = 2)  # Premium Plan

# Create a data frame
data <- data.frame(
  satisfaction = c(basic_plan, standard_plan, premium_plan),
  plan = factor(rep(c("Basic", "Standard", "Premium"), each = 30))
)

# Perform one-way ANOVA
anova_result <- aov(satisfaction ~ plan, data = data)
summary(anova_result)
```

**Interpretation:**

-   **Groups (Service Plans):**

    -   **Basic Plan:** Mean satisfaction score of 5

    -   **Standard Plan:** Mean satisfaction score of 6

    -   **Premium Plan:** Mean satisfaction score of 7

-   **ANOVA Summary:**

    -   **Df:** Degrees of freedom

    -   **Sum Sq:** Sum of squares

    -   **Mean Sq:** Mean squares

    -   **F value:** F statistic

    -   **Pr(\>F):** p-value for the F-test

**Conclusion:**

\- If the p-value is less than the significance level (e.g., 0.05), reject the null hypothesis.

Since the p-value (4.94e-5) is less than the common significance level (0.05), we reject the null hypothesis.

This indicates that there is a significant difference in customer satisfaction scores among the three service plans.

### 5. Chi-square Test for Independence

**Use:** To test if there is a significant association between two categorical variables.

**Assumptions:** - The data is in the form of counts or frequencies. - The observations are independent. - The expected frequency in each cell of the contingency table is at least 5.

**Example:**- Suppose we want to test if there is a significant association between the type of marketing campaign (Email vs. Social Media) and customer response (Purchased vs. Not Purchased).

**Code:**

```{r}
# Load necessary library
library(dplyr)

# Set seed for reproducibility
set.seed(123)

# Create a contingency table for marketing campaigns and customer response
# Rows: Customer Response (Purchased, Not Purchased)
# Columns: Marketing Campaign (Email, Social Media)
campaign_data <- matrix(c(20, 30, 50, 80), nrow = 2, byrow = TRUE)
colnames(campaign_data) <- c("Email", "Social Media")
rownames(campaign_data) <- c("Purchased", "Not Purchased")

# Print the contingency table
print(campaign_data)

# Perform chi-squared test
chi_square_result <- chisq.test(campaign_data)

# Print the test result
print(chi_square_result)
```

**Interpretation:**

\- If the p-value is less than the significance level (e.g., 0.05), reject the null hypothesis.

Here, the p-value is 0.9849, so we fail to reject the null hypothesis, indicating no significant association between the groups and categories.

This indicates that there is no significant association between the type of marketing campaign (Email vs. Social Media) and customer response (Purchased vs. Not Purchased).

### 6. Mann-Whitney U Test (Wilcoxon Rank-Sum Test)

**Use:** To compare the distributions of two independent samples when the assumptions for a t-test are not met.

**Assumptions:** - The samples are independent. - The data is ordinal or continuous. - The distributions of the two groups are similar in shape.

**Code:**

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate non-normally distributed sales performance scores for two sales teams using the exponential distribution
team_A_sales <- rexp(30, rate = 1/5)  # Sales performance scores for Team A
team_B_sales <- rexp(30, rate = 1/6)  # Sales performance scores for Team B

# Perform Wilcoxon Rank-Sum Test to compare the sales performance scores between Team A and Team B
wilcox_test_result <- wilcox.test(team_A_sales, team_B_sales)

# Print the sales performance scores
print(team_A_sales)
print(team_B_sales)

# Print the Wilcoxon Rank-Sum Test result
print(wilcox_test_result)

```

**Interpretation:**

-   **Sales Performance Scores:**

    -   **Team A:** Generated sales performance scores using the exponential distribution with a rate of 1/5.

    -   **Team B:** Generated sales performance scores using the exponential distribution with a rate of 1/6.

-   **Wilcoxon Rank-Sum Test Result:**

    -   **W:** Test statistic (308)

    -   **p-value:** Probability of observing the data if the null hypothesis is true (0.03577)

**Conclusion:** Since the p-value (0.03577) is less than the common significance level (0.05), we reject the null hypothesis.

This indicates that there is a significant difference in the sales performance scores between Team A and Team B.

**Determine where is the difference?**

To determine which side the difference lies on, we can look at the medians of the two groups and the alternative hypothesis of the Wilcoxon Rank-Sum Test. Here’s how you can interpret the results and determine which group has higher values:

1.  **Check the Medians of Both Groups:** Calculate and compare the medians of the two groups.
2.  **Interpret the Alternative Hypothesis:** The alternative hypothesis of the Wilcoxon Rank-Sum Test is that the true location shift between the two groups is not equal to zero. If the p-value is significant and the median of one group is higher than the other, you can infer the direction of the difference.

### Example: Determining the Direction of the Difference

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate non-normally distributed sales performance scores for two sales teams using the exponential distribution
team_A_sales <- rexp(30, rate = 1/5)  # Sales performance scores for Team A
team_B_sales <- rexp(30, rate = 1/6)  # Sales performance scores for Team B

# Perform Wilcoxon Rank-Sum Test to compare the sales performance scores between Team A and Team B
wilcox_test_result <- wilcox.test(team_A_sales, team_B_sales)

# Print the sales performance scores
print(team_A_sales)
print(team_B_sales)

# Print the Wilcoxon Rank-Sum Test result
print(wilcox_test_result)

# Calculate and print the medians of the two groups
median_A <- median(team_A_sales)
median_B <- median(team_B_sales)
print(paste("Median of Team A:", median_A))
print(paste("Median of Team B:", median_B))
```

### Interpretation:

-   **Medians:**
    -   **Median of Team A:** 3.60249855605114
    -   **Median of Team B:** 6.21641126927648
-   **Wilcoxon Rank-Sum Test Result:**
    -   **W:** Test statistic (308)
    -   **p-value:** 0.03577
    -   **Alternative Hypothesis:** True location shift is not equal to 0

**Conclusion:** Since the p-value (0.03577) is less than the significance level (0.05), we reject the null hypothesis, indicating that there is a significant difference in the sales performance scores between Team A and Team B.

Comparing the medians, Team B has a higher median sales performance score (6.216) compared to Team A (3.60). Therefore, Team B performs significantly better than Team A.

This approach helps us determine not only whether there is a significant difference but also which group has higher values based on their medians.

### 7. Wilcoxon Signed-Rank Test

**Use:** To compare the distributions of two related samples when the assumptions for a paired t-test are not met.

**Assumptions:** - The differences between the paired observations are symmetrically distributed. - The pairs are independent.

**Example:**- Suppose we want to test if a new process has significantly improved employee productivity scores by comparing their productivity before and after the implementation of the new process using a non-parametric test (Wilcoxon Signed-Rank Test).

**Code:**

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate non-normally distributed productivity scores before and after the implementation of a new process using the exponential distribution
productivity_before <- rexp(30, rate = 1/5)  # Productivity scores before the new process
productivity_after <- productivity_before + rexp(30, rate = 1/6)  # Productivity scores after the new process

# Perform Wilcoxon Signed-Rank Test to compare the productivity scores before and after the new process
wilcox_test_result <- wilcox.test(productivity_before, productivity_after, paired = TRUE)

# Print the productivity scores
print(productivity_before)
print(productivity_after)

# Print the Wilcoxon Signed-Rank Test result
print(wilcox_test_result)

# Calculate and print the medians of the two groups
median_before <- median(productivity_before)
median_after <- median(productivity_after)
print(paste("Median of Productivity Before:", median_before))
print(paste("Median of Productivity After:", median_after))
```

**Interpretation:**

-   **Productivity Scores:**

    -   **Before the New Process:** Generated productivity scores using the exponential distribution with a rate of 1/5.

    -   **After the New Process:** Generated productivity scores using the exponential distribution with a rate of 1/6.

-   **Wilcoxon Signed-Rank Test Result:**

    -   **V:** Test statistic (74)

    -   **p-value:** 1.863e-09

    -   **Alternative Hypothesis:** True location shift is not equal to 0

-   **Medians:**

    -   **Median of Productivity Before:** 3.6

    -   **Median of Productivity After:** 8.4

**Conclusion:** Since the p-value (1.863e-09) is less than the common significance level (0.05), we reject the null hypothesis.

This indicates that there is a significant difference in productivity scores before and after the implementation of the new process, with productivity increasing after the new process.

Comparing the medians, the productivity after the new process (3.6) is higher than before (8.4).

### 8. Kruskal-Wallis Test

**Use:** To compare the distributions of three or more independent groups when the assumptions for ANOVA are not met.

**Assumptions:**

\- The samples are independent.

\- The data is ordinal or continuous.

\- The distributions of the groups are similar in shape.

**Example:**- Suppose we want to test if there is a significant difference in customer satisfaction scores among three different service plans (Basic, Standard, and Premium) using a non-parametric test (Kruskal-Wallis Test).

**Code:**

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate customer satisfaction scores for three different service plans
basic_plan <- rnorm(30, mean = 5, sd = 2)     # Satisfaction scores for Basic Plan
standard_plan <- rnorm(30, mean = 6, sd = 2)  # Satisfaction scores for Standard Plan
premium_plan <- rnorm(30, mean = 7, sd = 2)   # Satisfaction scores for Premium Plan

# Create a data frame
data <- data.frame(
  satisfaction = c(basic_plan, standard_plan, premium_plan),
  plan = factor(rep(c("Basic", "Standard", "Premium"), each = 30))
)

# Perform Kruskal-Wallis Test to compare the satisfaction scores among the three service plans
kruskal_test_result <- kruskal.test(satisfaction ~ plan, data = data)

# Print the satisfaction scores
print(data)

# Print the Kruskal-Wallis Test result
print(kruskal_test_result)

# Calculate and print the medians of the three groups
median_basic <- median(basic_plan)
median_standard <- median(standard_plan)
median_premium <- median(premium_plan)
print(paste("Median of Basic Plan:", median_basic))
print(paste("Median of Standard Plan:", median_standard))
print(paste("Median of Premium Plan:", median_premium))

```

**Interpretation:**

-   **Customer Satisfaction Scores:**

    -   **Basic Plan:** Generated satisfaction scores with a mean of approximately 5.

    -   **Standard Plan:** Generated satisfaction scores with a mean of approximately 6.

    -   **Premium Plan:** Generated satisfaction scores with a mean of approximately 7.

-   **Kruskal-Wallis Test Result:**

    -   **Kruskal-Wallis chi-squared:** 17.693

    -   **Degrees of Freedom (df):** 2

    -   **p-value:** 0.0001439

-   **Medians:**

    -   **Median of Basic Plan:** 4.85

    -   **Median of Standard Plan:** 6.09

    -   **Median of Premium Plan:** 7.05

**Conclusion:** Since the p-value (0.0001439) is less than the common significance level (0.05), we reject the null hypothesis.

This indicates that there is a significant difference in customer satisfaction scores among the three service plans.

Comparing the medians, the Premium Plan has the highest median satisfaction score (7.05), followed by the Standard Plan (6.09), and then the Basic Plan (4.85).

------------------------------------------------------------------------

# Self Study

## **Determine the Appropriate Sample Size - Power Analysis**

Determining the appropriate sample size using power analysis involves specifying the significance level (alpha), the desired power (1 - beta), and the expected effect size.

Power analysis can be done using various statistical software tools, including R.

Here’s how you can perform power analysis in R to determine the sample size for a one-sample t-test.

### Steps to Perform Power Analysis in R

1.  **Define Parameters**:
    -   **Significance level (**α): Typically set at 0.05.

    -   **Power (1 -** β): Commonly set at 0.80 or 0.90.

    -   **Effect size (Cohen's d)**: Estimate of the standardized difference between the sample mean and the target mean.
2.  **Use the `power.t.test` Function**:
    -   This function calculates the required sample size based on the specified parameters.

### Example

Suppose you want to determine the sample size needed to detect a medium effect size (Cohen's d = 0.5) with a significance level of 0.05 and a power of 0.80 for a one-sample t-test.

```{r}
# Load necessary library
if (!requireNamespace("pwr", quietly = TRUE)) {
  install.packages("pwr")
}
library(pwr)

# Define parameters
alpha <- 0.05
power <- 0.80
effect_size <- 0.5

# Perform power analysis to determine the sample size
power_analysis <- power.t.test(delta = effect_size, sd = 1, sig.level = alpha, power = power, type = "one.sample", alternative = "two.sided")

# Print the result
cat("Required sample size:", ceiling(power_analysis$n), "\n")
```

### Explanation

-   **delta**: The expected effect size (Cohen's d). Here, we use 0.5 for a medium effect size.

-   **sd**: The standard deviation of the population. For simplicity, we assume it to be 1. If you have an estimate of the standard deviation from pilot studies or historical data, use that value.

-   **sig.level**: The significance level (α). Commonly set at 0.05.

-   **power**: The desired power (1 - β). Commonly set at 0.80.

-   **type**: Specifies the type of t-test. We use "one.sample" for a one-sample t-test.

-   **alternative**: Specifies the alternative hypothesis. We use "two.sided" for a two-tailed test.

### Conclusion

Using the `power.t.test` function in R, you can determine the appropriate sample size needed for your study based on the desired power, significance level, and expected effect size. This ensures that your experiment is adequately powered to detect a significant effect if one exists.

## Effect Size

Effect size is a quantitative measure of the magnitude of a phenomenon. It provides information about the strength or importance of a relationship, difference, or effect in a study, independent of sample size. Unlike p-values, which indicate whether an effect exists, effect sizes indicate the size of the effect. Effect sizes are used in various contexts, including hypothesis testing, meta-analysis, and power analysis.

### Types of Effect Size

1.  **Cohen's d**: Used to measure the difference between two means. It is often used in t-tests.
2.  **Pearson's r**: Measures the strength and direction of the linear relationship between two variables.
3.  **Eta squared (η²)**: Used in ANOVA to measure the proportion of total variance that is attributed to an effect.
4.  **Odds ratio**: Used in logistic regression to measure the odds of an outcome occurring in one group compared to another.
5.  **Cramér's V**: Used to measure the association between two nominal variables.

### Calculating Effect Size

#### Cohen's d

Cohen's d is calculated as the difference between two means divided by the pooled standard deviation:

\[ d = \frac{M_1 - M_2}{s_p} \]

where (M_1) and (M_2) are the means of the two groups, and (s_p) is the pooled standard deviation.

#### Pearson's r

Pearson's r is calculated as:

\[ r = \frac{\sum (X - \bar{X})(Y - \bar{Y})}{\sqrt{\sum (X - \bar{X})^2 \sum (Y - \bar{Y})^2}} \]

where (X) and (Y) are the variables, and (\bar{X}) and (\bar{Y}) are their respective means.

#### Eta squared (η²)

Eta squared is calculated as:

\[ \eta\^2 = \frac{SS_{effect}}{SS_{total}} \]

where (SS\_{effect}) is the sum of squares for the effect of interest, and (SS\_{total}) is the total sum of squares.

### Interpreting Effect Size

The interpretation of effect size depends on the context and the specific measure used. Here are some general guidelines for interpreting Cohen's d:

-   **Small effect**: (d \approx 0.2)
-   **Medium effect**: (d \approx 0.5)
-   **Large effect**: (d \approx 0.8)

For Pearson's r:

-   **Small effect**: (r \approx 0.1)
-   **Medium effect**: (r \approx 0.3)
-   **Large effect**: (r \approx 0.5)

### Example in R

Here's an example of calculating Cohen's d in R for two independent samples:

``` r
# Sample data
group1 <- c(2.9, 3.0, 3.2, 3.5, 3.7)
group2 <- c(3.8, 3.9, 4.0, 4.2, 4.3)

# Calculate means
mean1 <- mean(group1)
mean2 <- mean(group2)

# Calculate pooled standard deviation
sd1 <- sd(group1)
sd2 <- sd(group2)
n1 <- length(group1)
n2 <- length(group2)
pooled_sd <- sqrt(((n1 - 1) * sd1^2 + (n2 - 1) * sd2^2) / (n1 + n2 - 2))

# Calculate Cohen's d
cohens_d <- (mean1 - mean2) / pooled_sd
cat("Cohen's d:", cohens_d, "\n")
```

### Conclusion

Effect size is a crucial measure in statistical analysis as it provides insight into the practical significance of research findings. It is complementary to p-values and helps researchers understand the magnitude of observed effects. Various measures of effect size exist, each suitable for different types of data and analyses.

## Testing the Normality of Sample Data

To test the normality of a sample in R, you can use several methods, including visual inspection and statistical tests. Here's a step-by-step guide:

### 1. Visual Inspection

-   **Histogram**: Provides a graphical representation of the distribution.
-   **Q-Q Plot**: Compares the quantiles of the sample with the quantiles of a normal distribution.

### 2. Statistical Tests

-   **Shapiro-Wilk Test**: Commonly used for small to medium-sized samples.
-   **Kolmogorov-Smirnov Test**: Can be used but is less powerful than the Shapiro-Wilk Test for small samples.
-   **Anderson-Darling Test**: Another option, more sensitive to deviations in the tails of the distribution.

### Example Code

#### Generate a Sample

For demonstration, let’s assume you have a sample of 30 numbers. We’ll use the sample you provided:

```{r}
sample_data <- c(3.626294, 4.108676, 7.448164, 5.719628, 5.801543, 5.221365, 3.888318, 8.573826,5.995701, 1.066766, 6.402712, 4.054417, 2.864353, 4.564050, 2.947991, 3.542218,3.749921, 1.626613, 6.675574, 5.306746, 2.723726, 7.507630)
```

#### Visual Inspection

1.  **Histogram**:

    ```{r}
    # Histogram
    hist(sample_data, main = "Histogram of Sample Data", xlab = "Value", ylab = "Frequency", col = "lightblue", border = "black")
    ```

<!-- -->

2.  **Q-Q Plot**:

```{r}
# Q-Q Plot
qqnorm(sample_data)
qqline(sample_data, col = "red")
```

#### Statistical Tests

1.  **Shapiro-Wilk Test**:

The Shapiro-Wilk Test is a statistical test used to assess the normality of a dataset. It is particularly effective for small to medium-sized samples. The null hypothesis ((H_0)) of the Shapiro-Wilk Test is that the data follow a normal distribution, while the alternative hypothesis ((H_1)) is that the data do not follow a normal distribution. To perform the test, the data are compared to a perfectly normal distribution, and a W statistic is calculated. If the resulting p-value is greater than the chosen significance level (commonly 0.05), we fail to reject the null hypothesis, suggesting that the data are normally distributed. Conversely, if the p-value is less than the significance level, we reject the null hypothesis, indicating that the data deviate significantly from a normal distribution. This test is often used in preliminary data analysis to justify the use of parametric tests, which assume normality.

```{r}
# Shapiro-Wilk Test
shapiro_test <- shapiro.test(sample_data)
print(shapiro_test)
```

2.  **Kolmogorov-Smirnov Test**:

The Kolmogorov-Smirnov (K-S) Test is a non-parametric test used to determine if a sample comes from a specific distribution, most commonly a normal distribution. It compares the cumulative distribution function (CDF) of the sample data to the CDF of the reference distribution. The null hypothesis ((H_0)) of the K-S Test is that the sample data follow the specified distribution, while the alternative hypothesis ((H_1)) is that the sample data do not follow the specified distribution. To perform the test, the maximum distance between the empirical CDF of the sample and the CDF of the reference distribution is calculated. If the resulting p-value is greater than the chosen significance level (commonly 0.05), we fail to reject the null hypothesis, suggesting that the data follow the specified distribution. If the p-value is less than the significance level, we reject the null hypothesis, indicating a significant deviation from the specified distribution. This test is versatile and can be used to compare two samples or to test the goodness of fit for any theoretical distribution.

```{r}
# Kolmogorov-Smirnov Test
ks_test <- ks.test(sample_data, "pnorm", mean = mean(sample_data), sd = sd(sample_data))
print(ks_test)
```

3.  **Anderson-Darling Test** (requires the `nortest` package):

The Anderson-Darling Test is a statistical test used to assess whether a given sample of data comes from a specified distribution, typically a normal distribution. It is an enhancement of the Kolmogorov-Smirnov Test, giving more weight to the tails of the distribution. The null hypothesis ((H_0)) of the Anderson-Darling Test is that the data follow the specified distribution, while the alternative hypothesis ((H_1)) is that the data do not follow the specified distribution. The test calculates a statistic based on the differences between the observed and expected cumulative distribution functions, with a focus on the tails. A significant p-value (usually less than 0.05) leads to the rejection of the null hypothesis, indicating that the data do not follow the specified distribution. Conversely, a non-significant p-value means that we fail to reject the null hypothesis, suggesting that the data do follow the specified distribution. The Anderson-Darling Test is particularly useful for validating assumptions of normality in small to medium-sized datasets and for distributions with critical tail behavior.

```{r}
# Install and load nortest package
if (!requireNamespace("nortest", quietly = TRUE)) {
  install.packages("nortest")
}
library(nortest)

# Anderson-Darling Test
ad_test <- ad.test(sample_data)
print(ad_test)
```

### Complete R Code Example

Here's the complete R code to perform all these steps:

```{r}
# Load necessary library for Anderson-Darling test
if (!requireNamespace("nortest", quietly = TRUE)) {
  install.packages("nortest")
}
library(nortest)

# Sample data
sample_data <- c(3.626294, 4.108676, 7.448164, 5.719628, 5.801543, 5.221365, 3.888318, 8.573826,5.995701, 1.066766, 6.402712, 4.054417, 2.864353, 4.564050, 2.947991, 3.542218,3.749921, 1.626613, 6.675574, 5.306746, 2.723726, 7.507630)

# Histogram
hist(sample_data, main = "Histogram of Sample Data", xlab = "Value", ylab = "Frequency", col = "lightblue", border = "black")

# Q-Q Plot
qqnorm(sample_data)
qqline(sample_data, col = "red")

# Shapiro-Wilk Test
shapiro_test <- shapiro.test(sample_data)
print(shapiro_test)

# Kolmogorov-Smirnov Test
ks_test <- ks.test(sample_data, "pnorm", mean = mean(sample_data), sd = sd(sample_data))
print(ks_test)

# Anderson-Darling Test
ad_test <- ad.test(sample_data)
print(ad_test)
```

### Interpreting Results

-   **Histogram and Q-Q Plot**: These plots provide a visual assessment of normality. If the histogram resembles a bell curve and the points on the Q-Q plot fall approximately along the reference line, the data likely follow a normal distribution.
-   **Shapiro-Wilk Test**: Provides a p-value. If the p-value is greater than 0.05, we fail to reject the null hypothesis, suggesting that the data are normally distributed.
-   **Kolmogorov-Smirnov Test**: Provides a p-value. Similar interpretation as the Shapiro-Wilk Test.
-   **Anderson-Darling Test**: Provides a test statistic and a p-value. If the p-value is greater than 0.05, the null hypothesis that the data are normally distributed cannot be rejected.

By combining visual inspection with statistical tests, you can robustly assess the normality of your sample data.

## Determine if Variances are Equal or Not

To determine if variances are equal (homoscedasticity) or not (heteroscedasticity), several statistical tests can be used. The most common methods include the F-test, Levene's test, and Bartlett's test. Here's a brief overview of each method and how to perform them in R:

### 1. F-test

The F-test is used to compare the variances of two samples. It is sensitive to departures from normality.

**Null Hypothesis ((H_0))**: The variances are equal.

**Alternative Hypothesis ((H_1))**: The variances are not equal.

```{r}
# Sample data
sample1 <- c(2.9, 3.0, 3.2, 3.5, 3.7)
sample2 <- c(3.8, 3.9, 4.0, 4.2, 4.3)

# F-test
f_test_result <- var.test(sample1, sample2)
print(f_test_result)
```

### 2. Levene's Test

Levene's test is more robust to departures from normality and can be used to compare the variances of two or more samples.

**Null Hypothesis ((H_0))**: The variances are equal.

**Alternative Hypothesis ((H_1))**: The variances are not equal.

To use Levene's test in R, you need the `car` package:

```{r}
# Install and load the car package if not already installed
if (!requireNamespace("car", quietly = TRUE)) {
  install.packages("car")
}
library(car)

# Sample data
sample1 <- c(2.9, 3.0, 3.2, 3.5, 3.7)
sample2 <- c(3.8, 3.9, 4.0, 4.2, 4.3)

# Combine data into a data frame
data <- data.frame(
  value = c(sample1, sample2),
  group = factor(rep(1:2, each = length(sample1)))
)

# Levene's test
levene_test_result <- leveneTest(value ~ group, data)
print(levene_test_result)
```

### 3. Bartlett's Test

Bartlett's test is used to compare the variances of two or more samples, but it is sensitive to departures from normality.

**Null Hypothesis ((H_0))**: The variances are equal.

**Alternative Hypothesis ((H_1))**: The variances are not equal.

```{r}
# Sample data
sample1 <- c(2.9, 3.0, 3.2, 3.5, 3.7)
sample2 <- c(3.8, 3.9, 4.0, 4.2, 4.3)

# Bartlett's test
bartlett_test_result <- bartlett.test(list(sample1, sample2))
print(bartlett_test_result)
```

### Interpreting Results

-   **F-test**: If the p-value is less than the significance level (commonly 0.05), reject the null hypothesis, indicating that the variances are significantly different.
-   **Levene's Test**: If the p-value is less than the significance level, reject the null hypothesis, indicating that the variances are significantly different.
-   **Bartlett's Test**: If the p-value is less than the significance level, reject the null hypothesis, indicating that the variances are significantly different.

These tests help you determine whether the assumption of equal variances is valid, which is important for many statistical analyses, such as ANOVA and t-tests.

## Topics in Hypothesis Testing

#### 1. Introduction

-   Definition and Importance
-   Null Hypothesis (H0) and Alternative Hypothesis (H1)
-   Types of Errors
    -   Type I Error (False Positive)
    -   Type II Error (False Negative)
-   Significance Level (α)

#### 2. Steps in Hypothesis Testing

-   Formulating Hypotheses
-   Choosing the Appropriate Test
-   Determining the Significance Level
-   Calculating the Test Statistic
-   Making a Decision
-   Interpreting Results

#### 3. Types of Hypothesis Tests

-   One-tailed vs. Two-tailed Tests
    -   Definition and Differences
    -   When to Use Each Type

#### 4. Parametric Tests

-   Z-test
    -   One-sample Z-test
    -   Two-sample Z-test
    -   Assumptions and Applications
-   T-test
    -   One-sample T-test
    -   Independent Two-sample T-test
    -   Paired Sample T-test
    -   Assumptions and Applications
-   ANOVA (Analysis of Variance)
    -   One-way ANOVA
    -   Two-way ANOVA
    -   Assumptions and Applications

#### 5. Non-parametric Tests

-   Chi-square Test
    -   Chi-square Test for Independence
    -   Chi-square Goodness of Fit Test
    -   Assumptions and Applications
-   Mann-Whitney U Test
    -   Definition and Application
-   Wilcoxon Signed-Rank Test
    -   Definition and Application
-   Kruskal-Wallis Test
    -   Definition and Application

#### 6. Test Assumptions and Conditions

-   Normality
-   Homogeneity of Variances
-   Independence
-   Handling Violations of Assumptions

#### 7. Power of a Test

-   Definition and Importance
-   Factors Affecting Power
-   Calculating and Interpreting Power

#### 8. P-value and Statistical Significance

-   Definition and Interpretation
-   Misconceptions and Common Pitfalls

#### 9. Effect Size

-   Definition and Importance
-   Common Measures of Effect Size (Cohen's d, Pearson's r, etc.)

#### 10. Hypothesis Testing in R

-   Conducting Z-tests and T-tests
-   Performing ANOVA
-   Running Chi-square Tests
-   Implementing Non-parametric Tests
-   Visualizing Test Results

Open the sample dataset

```{r}
library(dplyr)
library(readr)

file_path <- "data\\superstore.csv"
superstore <- read_csv(file_path, show_col_types = FALSE)
```

### 1. Correlation Analysis

**Introduction**: - Correlation analysis measures the strength and direction of the relationship between two variables. For instance, you can analyze the correlation between sales and profit, or discount and profit.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(GGally)  
# Select relevant numeric columns 
numeric_data <- superstore %>%   select(Sales, Profit, Discount, Quantity)  
# Calculate correlation matrix 
correlation_matrix <- cor(numeric_data)  
# Visualize the correlation matrix 
ggcorr(numeric_data, label = TRUE)
```

The **`ggcorr()`** function is part of the **`GGally`** package in R, which extends **`ggplot2`** for easy creation of complex plots. **`GGally`** is particularly useful for visualizing relationships between multiple variables in a dataset.

The **`ggcorr()`** function is used to visualize a correlation matrix. It plots the correlation coefficients between variables, offering an intuitive graphical representation of how variables are related in terms of linear correlation.

The image shows a correlation matrix for the variables Sales, Profit, Discount, and Quantity. Here’s an interpretation of the correlation coefficients presented in the plot:

1.  **Sales**:
    -   **Profit**: There is a positive correlation of 0.5 between Sales and Profit. This indicates a moderate positive relationship, meaning as sales increase, profit tends to increase as well.
    -   **Discount**: The correlation between Sales and Discount is 0. This suggests no linear relationship between sales and discount.
    -   **Quantity**: There is a positive correlation of 0.2 between Sales and Quantity. This indicates a weak positive relationship, meaning as the quantity increases, sales also tend to increase slightly.
2.  **Profit**:
    -   **Discount**: There is a negative correlation of -0.2 between Profit and Discount. This indicates a weak negative relationship, meaning higher discounts are associated with slightly lower profits.
    -   **Quantity**: There is a positive correlation of 0.1 between Profit and Quantity. This indicates a very weak positive relationship, suggesting a slight tendency for profit to increase with quantity.
3.  **Discount**:
    -   **Quantity**: The correlation between Discount and Quantity is 0. This suggests no linear relationship between discount and quantity.

### Key Insights:

-   **Sales and Profit**: The moderate positive correlation (0.5) indicates that as sales increase, profit tends to increase as well, which is expected in most business scenarios.
-   **Profit and Discount**: The weak negative correlation (-0.2) suggests that increasing discounts slightly reduce profit, which makes sense because higher discounts reduce the revenue per sale.
-   **Sales and Quantity**: The weak positive correlation (0.2) indicates that selling more items tends to increase total sales, though the relationship is not very strong.

### Color Scale:

-   The color scale on the right indicates the strength and direction of the correlation:
    -   Red indicates positive correlations.
    -   Blue indicates negative correlations.
    -   The intensity of the color corresponds to the strength of the correlation, with darker colors indicating stronger correlations.

This correlation matrix helps to understand the relationships between key variables in your dataset and can guide further analysis or business decisions.

### 2. Regression Analysis: Linear Regression Example

**Introduction**: - Linear regression models the relationship between a dependent variable and one or more independent variables. You can use it to predict profit based on discount and quantity.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2)  

# Fit a linear regression model to predict Profit based on Discount and Quantity
regression_model <- lm(Profit ~ Discount + Quantity, data = superstore)  
# Summarize the regression model 

summary(regression_model)  

# Plot the regression results 
ggplot(superstore, aes(x = Discount, y = Profit)) +   
  geom_point() +   
  geom_smooth(method = "lm", se = FALSE) +   
  labs(title = "Linear Regression: Profit vs. Discount", x = "Discount", y = "Profit")
```

The results of the linear regression and the corresponding plot can be interpreted as follows:

### Regression Results:

1.  **Model Summary**:
    -   **Residuals**:
        -   The distribution of residuals provides insights into the model's fit. The range is from -6501.5 to 8323.6, indicating some outliers.
    -   **Coefficients**:
        -   **Intercept**:
            -   Estimate: 40.494
            -   Std. Error: 4.811
            -   t value: 8.417
            -   Pr(\>\|t\|): \< 2e-16 (highly significant)
        -   **Discount**:
            -   Estimate: -249.758
            -   Std. Error: 11.047
            -   t value: -22.608
            -   Pr(\>\|t\|): \< 2e-16 (highly significant)
        -   **Quantity**:
            -   Estimate: 7.174
            -   Std. Error: 1.025
            -   t value: 6.999
            -   Pr(\>\|t\|): 2.74e-12 (highly significant)
2.  **Significance Codes**:
    -   The significance codes indicate the level of significance for each predictor.
    -   Both Discount and Quantity are highly significant predictors of Profit (p-values \< 0.001).
3.  **Model Fit**:
    -   **Residual standard error**: 228 on 9993 degrees of freedom
    -   **Multiple R-squared**: 0.05283
    -   **Adjusted R-squared**: 0.05264
    -   **F-statistic**: 278.7 on 2 and 9993 DF
    -   **p-value**: \< 2.2e-16 (highly significant overall model)

### Interpretation:

1.  **Intercept**:
    -   The intercept of 40.494 suggests that when both Discount and Quantity are zero, the expected Profit is 40.494.
2.  **Discount**:
    -   The coefficient for Discount is -249.758. This indicates that for each unit increase in Discount, Profit decreases by approximately 249.758 units, holding Quantity constant. The negative coefficient and highly significant p-value suggest a strong inverse relationship between Discount and Profit.
3.  **Quantity**:
    -   The coefficient for Quantity is 7.174. This indicates that for each additional unit sold, Profit increases by approximately 7.174 units, holding Discount constant. The positive coefficient and highly significant p-value suggest a direct relationship between Quantity and Profit.
4.  **Model Fit**:
    -   The Multiple R-squared value of 0.05283 indicates that approximately 5.28% of the variability in Profit is explained by the model. This is relatively low, suggesting that there are other factors affecting Profit that are not included in the model.
    -   The F-statistic and its p-value indicate that the overall model is significant, meaning at least one of the predictors (Discount or Quantity) significantly contributes to the model.

### Plot Interpretation:

The plot of Profit vs. Discount with a linear regression line (using `geom_smooth()`) provides a visual representation of the relationship between Profit and Discount. The line appears almost flat, indicating that while the relationship is statistically significant, the effect size may not be large enough to be visually apparent.

### Conclusion:

The regression analysis shows that both Discount and Quantity are significant predictors of Profit. Discounts have a negative impact on Profit, while higher quantities sold have a positive impact. However, the model explains only a small portion of the variability in Profit, indicating that other factors also play a significant role in determining Profit.

### 3. Logistic Regression

**Introduction**: - Logistic regression models the probability of a binary outcome, such as whether an order was profitable (profit \> 0) based on predictors like discount, quantity, and ship mode.

**R Code**:

```{r}
# Load necessary libraries 

library(dplyr) 
library(ggplot2) 
library(broom)  

# Create a binary outcome for profitability 
superstore <- superstore %>%   mutate(Profitable = ifelse(Profit > 0, 1, 0))  

# Logistic Regression: Profitable by Discount, Quantity, and Ship Mode
logistic_model <- glm(Profitable ~ Discount + Quantity + `Ship Mode`, data = superstore, family = binomial) 

summary(logistic_model)  

# Extract and view model results 
tidy(logistic_model)
```

The results shown are from a logistic regression model (generalized linear model with a binomial family) predicting whether an order is profitable (`Profitable`) based on the discount applied (`Discount`), the quantity ordered (`Quantity`), and the shipping mode (`Ship Mode`). Here is the interpretation of the results:

### Coefficients:

1.  **Intercept**:
    -   **Estimate**: 6.08655
    -   **Std. Error**: 0.21508
    -   **z value**: 28.299
    -   **Pr(\>\|z\|)**: \< 2e-16 (highly significant)
    -   **Interpretation**: When Discount and Quantity are zero, and the shipping mode is the baseline category (presumably "First Class"), the log-odds of an order being profitable is 6.08655.
2.  **Discount**:
    -   **Estimate**: -22.81549
    -   **Std. Error**: 0.84425
    -   **z value**: -27.025
    -   **Pr(\>\|z\|)**: \< 2e-16 (highly significant)
    -   **Interpretation**: For each unit increase in Discount, the log-odds of an order being profitable decreases by 22.81549. This strong negative coefficient suggests that higher discounts significantly decrease the probability of an order being profitable.
3.  **Quantity**:
    -   **Estimate**: 0.03915
    -   **Std. Error**: 0.01920
    -   **z value**: 2.040
    -   **Pr(\>\|z\|)**: 0.0414 (significant at the 0.05 level)
    -   **Interpretation**: For each additional unit ordered, the log-odds of an order being profitable increases by 0.03915. This suggests that higher quantities slightly increase the probability of an order being profitable.
4.  **Ship Mode: Same Day**:
    -   **Estimate**: 0.02501
    -   **Std. Error**: 0.20646
    -   **z value**: 0.121
    -   **Pr(\>\|z\|)**: 0.9036 (not significant)
    -   **Interpretation**: The log-odds of an order being profitable for "Same Day" shipping mode compared to the baseline category is 0.02501. This effect is not statistically significant.
5.  **Ship Mode: Second Class**:
    -   **Estimate**: 0.12507
    -   **Std. Error**: 0.14437
    -   **z value**: 0.866
    -   **Pr(\>\|z\|)**: 0.3863 (not significant)
    -   **Interpretation**: The log-odds of an order being profitable for "Second Class" shipping mode compared to the baseline category is 0.12507. This effect is not statistically significant.
6.  **Ship Mode: Standard Class**:
    -   **Estimate**: -0.16989
    -   **Std. Error**: 0.11635
    -   **z value**: -1.460
    -   **Pr(\>\|z\|)**: 0.1442 (not significant)
    -   **Interpretation**: The log-odds of an order being profitable for "Standard Class" shipping mode compared to the baseline category is -0.16989. This effect is not statistically significant.

### Model Summary:

-   **Null Deviance**: 9826.3 on 9995 degrees of freedom
    -   This represents the fit of a model with only an intercept (no predictors).
-   **Residual Deviance**: 3919.1 on 9990 degrees of freedom
    -   This represents the fit of the model with all the predictors included. A lower value indicates a better fit.
-   **AIC (Akaike Information Criterion)**: 3931.1
    -   A lower AIC value indicates a better-fitting model.

### Interpretation:

1.  **Significant Predictors**:
    -   **Discount**: Highly significant with a strong negative impact on the probability of an order being profitable.
    -   **Quantity**: Significant with a small positive impact on the probability of an order being profitable.
2.  **Non-Significant Predictors**:
    -   **Ship Mode**: None of the shipping modes ("Same Day", "Second Class", "Standard Class") are statistically significant predictors of profitability compared to the baseline category.
3.  **Model Fit**:
    -   The significant reduction in deviance from the null model (9826.3) to the residual model (3919.1) suggests that the model with predictors fits the data significantly better than the null model.
    -   The number of Fisher Scoring iterations (8) indicates that the model converged successfully.

### Conclusion:

The logistic regression model indicates that Discount and Quantity are significant predictors of order profitability, with Discount having a strong negative impact and Quantity having a slight positive impact. The different shipping modes do not appear to have a significant effect on profitability. This information can help in making informed decisions about discount strategies and inventory management to optimize profitability.

### 4. Clustering: K-Means Clustering Example

**Introduction**: - K-means clustering partitions the data into k clusters, where each data point belongs to the cluster with the nearest mean. This can be used to group customers based on purchasing behavior.

**R Code**:

```{r}
# Load necessary libraries  
library(dplyr)  
library(ggplot2)   

# Select relevant columns and scale the data   
customer_data <- superstore %>% group_by(`Customer ID`) %>%  
  summarise(Total_Sales = sum(Sales), Total_Orders = n()) %>%   
  ungroup()    

scaled_data <- scale(customer_data %>% select(Total_Sales, Total_Orders))    

# Perform k-means clustering with 3 clusters  
set.seed(123) 
kmeans_result <- kmeans(scaled_data, centers = 3)    

# Add cluster assignment to the original data  
customer_data$Cluster <- as.factor(kmeans_result$cluster)    

# Visualize the clusters  
ggplot(customer_data, aes(x = Total_Sales, y = Total_Orders, color = Cluster)) +  
  geom_point() + 
  labs(title = "K-Means Clustering: Customers", x = "Total Sales", y = "Total Orders")
```

The plot displays the results of a K-Means clustering analysis on customers, segmented by `Total Sales` and `Total Orders`. Each customer is assigned to one of three clusters, represented by different colors: red, green, and blue.

### Interpretation:

1.  **Clusters**:
    -   **Cluster 1 (Red)**: Customers in this cluster tend to have higher total sales, with values ranging from approximately 5,000 to 25,000. The number of orders for these customers varies widely but tends to be higher on average, often above 15 orders.
    -   **Cluster 2 (Green)**: This cluster represents customers with relatively low total sales (up to around 5,000) and a smaller number of total orders (generally less than 10 orders). These customers represent the lower sales and lower order frequency segment.
    -   **Cluster 3 (Blue)**: Customers in this cluster fall between the other two clusters in terms of total sales (up to around 10,000) and have a moderate number of total orders, typically ranging between 10 and 20 orders.
2.  **Cluster Characteristics**:
    -   **Cluster 1**: High-value customers who make significant purchases (high total sales) and place many orders. These might be your most valuable customers in terms of revenue.
    -   **Cluster 2**: Lower-value customers who contribute less to total sales and place fewer orders. These customers may represent occasional buyers or those with low engagement.
    -   **Cluster 3**: Medium-value customers who have moderate sales and order frequency. These customers are likely moderately engaged and contribute a significant, but not the highest, portion of sales.
3.  **Business Implications**:
    -   **Targeting and Marketing**:
        -   **Cluster 1**: These high-value customers should be prioritized for loyalty programs, special offers, and personalized marketing to retain and further engage them.
        -   **Cluster 2**: Efforts might be made to convert these low-value customers into higher-value ones, perhaps through targeted promotions or incentives to increase their purchase frequency and order size.
        -   **Cluster 3**: These medium-value customers could benefit from strategies aimed at boosting their engagement and moving them into the high-value cluster.
4.  **Visualization Insights**:
    -   The clear separation between clusters suggests that the K-Means algorithm has effectively grouped customers based on their sales and ordering behavior.
    -   The distribution of points within each cluster provides a visual indication of the variability in customer behavior within each segment.

### Conclusion:

The K-Means clustering analysis has segmented customers into three distinct groups based on their total sales and total orders. Each cluster represents a different level of customer value and engagement, providing insights that can guide targeted marketing strategies, customer relationship management, and business decision-making to optimize sales and customer satisfaction.

### 5. Principal Component Analysis (PCA)

**Introduction**: - Principal Component Analysis (PCA) reduces the dimensionality of our dataset while preserving as much variability as possible, which can help in visualizing high-dimensional data.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(FactoMineR)
library(factoextra)  

# Select numeric columns for PCA 
numeric_data <- superstore %>%  select(Sales, Profit, Discount, Quantity)  

# Perform PCA 
pca_result <- PCA(numeric_data, graph = FALSE)  

# Visualize PCA 
fviz_pca_var(pca_result, col.var = "contrib", gradient.cols = c("blue", "red"))
```

The image displays the results of a Principal Component Analysis (PCA) on selected numeric columns (`Sales`, `Profit`, `Discount`, `Quantity`) from the dataset.

Here is the interpretation of the PCA plot:

### Interpretation of the PCA Plot:

1.  **Principal Components (Dimensions)**:
    -   **Dim1 (PC1)**: The first principal component, which explains 39.7% of the variance in the data.
    -   **Dim2 (PC2)**: The second principal component, which explains 26.5% of the variance in the data.
    -   Together, these two components explain a significant portion (66.2%) of the total variance in the data, indicating that PCA has effectively reduced the dimensionality while retaining most of the variability.
2.  **Variable Contributions**:
    -   **Sales** and **Profit** have strong positive loadings on Dim1, suggesting that they are positively correlated and contribute similarly to this principal component.
    -   **Discount** has a strong negative loading on Dim1, indicating that it is inversely related to Sales and Profit.
    -   **Quantity** has a positive loading on Dim2, suggesting it is primarily explained by this second component.
3.  **Correlation and Relationships**:
    -   The length and direction of the arrows represent the strength and direction of the correlation between the variables and the principal components.
    -   **Sales** and **Profit** arrows point in the same direction, indicating a strong positive correlation.
    -   **Discount** points in the opposite direction to **Sales** and **Profit**, indicating an inverse relationship with these variables.
    -   **Quantity** points in a different direction, indicating it has a distinct contribution to the variance explained by Dim2.
4.  **Color Gradient (Contribution)**:
    -   The color gradient from blue to red indicates the contribution of each variable to the principal components. Variables with darker red arrows contribute more to the principal components.

### Insights from the PCA:

1.  **Dimension 1 (Dim1)**:
    -   Captures the trade-off between high Sales and Profit versus high Discounts.
    -   A high score on Dim1 indicates higher Sales and Profit and lower Discount, while a low score indicates the opposite.
2.  **Dimension 2 (Dim2)**:
    -   Captures the variance primarily explained by Quantity.
    -   A high score on Dim2 indicates higher Quantity.

### Practical Implications:

1.  **Sales and Profit**:
    -   These two variables are strongly positively correlated, meaning that as sales increase, profits also increase, which is expected in most business contexts.
2.  **Discount**:
    -   There is a strong inverse relationship between Discount and both Sales and Profit, suggesting that higher discounts might be associated with lower sales and profit.
3.  **Quantity**:
    -   Quantity has a different pattern compared to the other variables, indicating it captures a unique aspect of the data variability.

### Conclusion:

The PCA plot provides a clear visualization of the relationships between Sales, Profit, Discount, and Quantity.

It shows that Sales and Profit are positively correlated and both inversely related to Discount.

Quantity contributes to the second dimension, indicating its unique contribution to the overall variance.

This analysis helps in understanding the underlying structure of the data and can guide further decision-making and strategic planning.

### 6. Hierarchical Clustering

**Introduction**: - Hierarchical clustering creates a hierarchy of clusters, which can help identify similar groups within your data, such as states or cities based on sales and profit.

**R Code**:

```{r}

# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(cluster) 
library(factoextra)  

# Aggregate data by state 
state_data <- superstore %>%   group_by(State) %>% summarise(Total_Sales = sum(Sales), Total_Profit = sum(Profit))  

# Scale the data 
scaled_data <- scale(state_data %>% select(Total_Sales, Total_Profit))  

# Perform hierarchical clustering 
hc <- hclust(dist(scaled_data))  

# Visualize the dendrogram 
fviz_dend(hc, k = 4, rect = TRUE, show_labels = TRUE)
```

The image shows the results of hierarchical clustering on state-level data based on total sales and total profit. Here is the interpretation of the dendrogram:

### Interpretation of the Dendrogram:

1.  **Dendrogram Structure**:
    -   The dendrogram represents the hierarchy of clusters formed by the hierarchical clustering algorithm.
    -   The height at which two clusters are joined indicates the dissimilarity (or distance) between them. Higher joins represent more dissimilar clusters.
2.  **Clusters**:
    -   The dendrogram shows four clusters, as indicated by the colored rectangles and the `k = 4` parameter in the `fviz_dend` function.
    -   The colors represent different clusters. Each cluster groups states that are similar in terms of their total sales and total profit.
3.  **Cluster Heights**:
    -   The y-axis (height) represents the distance or dissimilarity between clusters.
    -   Taller heights indicate greater dissimilarity between the clusters being joined.
    -   Shorter heights indicate that the clusters are more similar to each other.
4.  **Cluster Characteristics**:
    -   **Cluster 1 (Red)**: Contains states with relatively high dissimilarity compared to other states.
    -   **Cluster 2 (Green)**: Groups states with moderate sales and profit.
    -   **Cluster 3 (Blue)**: Contains the majority of states, indicating that these states have similar sales and profit characteristics.
    -   **Cluster 4 (Purple)**: Groups states with specific similar characteristics, likely outliers or unique patterns in sales and profit.

### Practical Implications:

1.  **Identifying Similar States**:
    -   The clustering helps identify groups of states that have similar sales and profit patterns.
    -   This can be useful for regional marketing strategies, sales forecasting, and resource allocation.
2.  **Understanding Outliers**:
    -   States in Cluster 1 (Red) and Cluster 4 (Purple) may be outliers or have unique sales and profit characteristics.
    -   These states might require special attention or tailored strategies.
3.  **Resource Allocation**:
    -   By understanding which states belong to which clusters, businesses can allocate resources more efficiently.
    -   For example, states in Cluster 3 (Blue) might benefit from a uniform marketing strategy, while states in Cluster 1 (Red) might need a customized approach.

### Conclusion:

The hierarchical clustering analysis provides a clear visualization of how states are grouped based on their sales and profit.

The dendrogram reveals four distinct clusters, indicating different patterns of sales and profit among the states.

This analysis can guide strategic decisions in marketing, sales, and resource allocation to optimize performance across different regions.

### 7. Time Series Decomposition

**Introduction**: - Time series decomposition separates a time series into trend, seasonal, and residual components, which helps understand underlying patterns in the data.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(forecast)  

# Ensure the 'Order Date' column is in Date format
superstore <- superstore %>%
  mutate(`Order Date` = as.Date(`Order Date`, format = "%m/%d/%Y"))  # Adjust the format as needed

# Aggregate sales data by month 
monthly_sales <- superstore %>% 
  group_by(Month = format(`Order Date`, "%Y-%m")) %>%   
  summarise(Total_Sales = sum(Sales))  

# Convert to time series object 
sales_ts <- ts(monthly_sales$Total_Sales, start = c(2014, 1), frequency = 12)  

# Decompose time series 
decomposed <- decompose(sales_ts)  

# Plot decomposition 
autoplot(decomposed)
```

The image shows the results of a time series decomposition of total sales, separating the time series into trend, seasonal, and residual components. Here is the interpretation of each component shown in the decomposition plot:

### Interpretation of the Decomposition Plot:

1.  **Data**:
    -   The top panel shows the original time series data for total sales from 2014 to 2018.
    -   This represents the raw data with all its variability, including trends, seasonality, and random noise.
2.  **Trend**:
    -   The second panel shows the trend component, which captures the long-term movement in the data.
    -   The trend indicates that total sales have been generally increasing over the period, with some fluctuations.
    -   The increase is more noticeable starting around mid-2015 and continues upwards towards the end of 2017.
3.  **Seasonal**:
    -   The third panel shows the seasonal component, which captures the repeating patterns or cycles within a year.
    -   There are clear seasonal fluctuations in sales, with peaks and troughs repeating annually.
    -   The seasonality indicates that sales tend to be higher at certain times of the year and lower at others, following a consistent pattern each year.
4.  **Remainder (Residual)**:
    -   The bottom panel shows the remainder component, which captures the irregular fluctuations after removing the trend and seasonal components.
    -   These are the random noise or unexpected variations in the data.
    -   The residuals should ideally have no clear pattern and be randomly distributed around zero.

### Practical Implications:

1.  **Understanding Trends**:
    -   The upward trend indicates that total sales have been increasing over the analyzed period. This positive trend is a good sign for business growth.
2.  **Seasonal Patterns**:
    -   The presence of clear seasonal patterns suggests that certain times of the year consistently experience higher or lower sales.
    -   Understanding these patterns can help in planning inventory, marketing campaigns, and resource allocation to maximize sales during peak periods and manage lower sales periods effectively.
3.  **Managing Irregular Variations**:
    -   By isolating the residual component, businesses can identify unusual fluctuations that are not explained by the trend or seasonal patterns.
    -   Analyzing these residuals can help in identifying specific events or anomalies that impact sales, allowing for more targeted interventions.

### Conclusion:

The time series decomposition provides valuable insights into the underlying patterns in the total sales data.

The increasing trend indicates overall growth, while the seasonal component reveals regular fluctuations throughout the year.

The residual component highlights the random noise, helping to isolate and understand irregular variations.

These insights can guide strategic planning, resource allocation, and marketing efforts to optimize sales performance.

### 8. Cox Proportional Hazards Model

**Introduction**: - The Cox Proportional Hazards Model is used to model the time until an event occurs, such as the time until a customer makes a repeat purchase.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(survival) 
library(ggplot2) 
library(survminer)  

# Assume we have a customer data frame with columns: Customer_ID, Order_Date, and Repeat_Purchase (1 if repeat, 0 if not) 

# Create a sequence of dates from January 2014 to December 2017
order_dates <- seq(as.Date("2014-01-01"), as.Date("2017-12-31"), by = "month")

# Repeat this sequence to ensure we have 1000 dates
order_dates <- rep(order_dates, length.out = 1000)

# Create the customer data
set.seed(123)
customer_data <- data.frame(
  Customer_ID = rep(1:100, each = 10),
  Order_Date = order_dates,
  Repeat_Purchase = sample(0:1, 1000, replace = TRUE)
)

# Create a survival object 
surv_object <- Surv(time = as.numeric(customer_data$Order_Date), event = customer_data$Repeat_Purchase)  

# Fit Cox proportional hazards model 
cox_model <- coxph(surv_object ~ Customer_ID, data = customer_data) 
summary(cox_model)  
```

### Interpretation of the Cox Proportional Hazards Model Results

The output shows the results of a Cox proportional hazards model applied to the customer data, which includes the `Customer_ID`, `Order_Date`, and `Repeat_Purchase` variables. Here is a detailed interpretation of the results:

#### Cox Model Summary:

The Cox proportional hazards model is used to evaluate the effect of customer ID on the likelihood of repeat purchases over time.

**Model Fit:** - The model was fit with 1000 observations and 494 events (repeat purchases).

**Coefficient (coef):** - `Customer_ID`: The coefficient for `Customer_ID` is -2.119e-05, which is very close to zero. This suggests that there is no substantial effect of customer ID on the hazard (risk) of repeat purchases.

**Exponentiated Coefficient (exp(coef)):** - `exp(coef)` for `Customer_ID` is 1.000e+00, which equals 1. This means that the hazard ratio for customer ID is 1, indicating no change in hazard with changes in customer ID.

**Standard Error (se(coef)):** - The standard error for `Customer_ID` is 1.580e-03, which is relatively small but given the coefficient is near zero, the effect is still insignificant.

**Wald Test Statistic (z):** - The z-value for `Customer_ID` is -0.013, which is close to zero. This indicates that the effect of customer ID on the hazard is not statistically significant.

**P-value (Pr(\>\|z\|)):** - The p-value for `Customer_ID` is 0.989, which is much greater than the common significance level (e.g., 0.05). This means we fail to reject the null hypothesis that the coefficient is zero, indicating no significant effect of customer ID on repeat purchase.

**Confidence Intervals:** - The 95% confidence interval for `exp(coef)` ranges from 0.9969 to 1.003. Since this interval includes 1, it further indicates that the effect of customer ID on the hazard is not statistically significant.

**Model Statistics:** - **Concordance:** 0.503 (se = 0.015): The concordance index measures the predictive accuracy of the model. A value of 0.503 suggests that the model has about a 50.3% chance of correctly ranking pairs of observations by their risk, which is slightly better than random chance (0.5). - **Likelihood ratio test:** 0 on 1 df, p=1: This test assesses the overall significance of the model. A p-value of 1 indicates that the model is not significantly better than a null model (with no predictors). - **Wald test:** 0 on 1 df, p=1: This test assesses the significance of the individual predictors. A p-value of 1 again indicates no significant effect. - **Score (logrank) test:** 0 on 1 df, p=1: This test is another method to assess the overall significance of the model, with the same conclusion that the model is not significant.

#### Practical Implications:

**No Significant Effect of Customer ID:** - The analysis indicates that customer ID does not have a significant effect on the likelihood of repeat purchases. This suggests that other factors, not included in the model, might be driving repeat purchases.

**Model Performance:** - The model's concordance index is close to 0.5, indicating it does not perform much better than random chance in predicting repeat purchases.

**Strategic Decisions:** - Since customer ID is not a significant predictor of repeat purchases, it might be beneficial to explore other variables such as purchase frequency, product categories, customer demographics, or engagement metrics to better understand and predict repeat purchase behavior.

**Future Analysis:** - Additional data and more complex models (including interaction terms or non-linear effects) might be necessary to capture the factors influencing repeat purchases.

**Conclusion:** - The current Cox proportional hazards model does not find a significant relationship between customer ID and repeat purchase behavior. Future analyses should consider other potential predictors to improve the understanding and prediction of repeat purchases.

**The Cox Proportional Hazards Model vs The Exponential Distribution**

The Cox Proportional Hazards Model and the exponential distribution are both used to model time-to-event data, but they serve different purposes and have different properties. Here's a comparison to clarify their similarities and differences:

### Cox Proportional Hazards Model

-   **Purpose:** The Cox Proportional Hazards Model is used to investigate the relationship between the time until an event occurs (such as time until a customer makes a repeat purchase) and one or more predictor variables (covariates).
-   **Model Form:** It is a semi-parametric model, meaning it makes no assumptions about the baseline hazard function (which can vary over time), but it assumes that the effect of the covariates on the hazard is multiplicative and constant over time.
-   **Hazard Function:** The model estimates hazard ratios, which describe the effect of covariates on the hazard of the event occurring.
-   **Flexibility:** The Cox model can handle time-varying covariates and allows for the inclusion of multiple covariates to adjust for confounding factors.
-   **Interpretation:** It provides hazard ratios for each covariate, indicating the relative risk of the event occurring for different values of the covariate.

### Exponential Distribution

-   **Purpose:** The exponential distribution is a continuous probability distribution used to model the time between events in a Poisson process, where events occur continuously and independently at a constant average rate.
-   **Model Form:** It is a parametric model with a single parameter (the rate parameter, λ), which is the inverse of the mean time between events.
-   **Hazard Function:** The hazard function for the exponential distribution is constant over time (λ). This implies that the event rate is the same at all times, which is a strong assumption.
-   **Flexibility:** It is less flexible than the Cox model because it assumes a constant hazard rate over time.
-   **Interpretation:** The rate parameter, λ, indicates the average rate at which events occur, and the mean time between events is 1/λ.

### Key Differences

-   **Assumptions:** The Cox model does not assume a specific form for the baseline hazard function, while the exponential distribution assumes a constant hazard rate.
-   **Flexibility:** The Cox model can handle multiple covariates and their effects on the hazard, whereas the exponential distribution is typically used for simpler models with a constant event rate.
-   **Applications:** The Cox model is widely used in survival analysis and epidemiology to assess the impact of covariates on survival times. The exponential distribution is often used in reliability engineering and queuing theory to model the time between failures or arrivals.

### Example Comparison

**Cox Proportional Hazards Model Example:**

``` r
# Fit Cox proportional hazards model
cox_model <- coxph(Surv(time, status) ~ age + sex, data = lung)
summary(cox_model)
```

**Exponential Distribution Example:**

``` r
# Fit exponential distribution to time-to-event data
time_to_event <- rexp(100, rate = 0.1)
hist(time_to_event, breaks = 20, main = "Histogram of Exponential Data", xlab = "Time to Event")
```

In summary, while both the Cox Proportional Hazards Model and the exponential distribution are used for modeling time-to-event data, the Cox model is more flexible and robust for handling complex relationships with multiple covariates, whereas the exponential distribution is simpler and assumes a constant hazard rate over time.

### 9. Survival Analysis

**Introduction**: - Survival analysis estimates the expected duration of time until one or more events occur, such as customer churn.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(survival) 
library(ggplot2) 
library(survminer)  
  
# Assume we have a customer data frame with columns: Customer_ID, Order_Date, and Churn (1 if churn, 0 if not)
  
# Create a sequence of dates from January 2014 to December 2017
order_dates <- seq(as.Date("2014-01-01"), as.Date("2017-12-31"), by = "month")
  
# Repeat this sequence to ensure we have 1000 dates
order_dates <- rep(order_dates, length.out = 1000)
  
# Create a dummy dataset for illustration purposes 
customer_data <- data.frame(Customer_ID = rep(1:100, each = 10),   Order_Date = order_dates, Churn = sample(0:1, 1000, replace = TRUE) )  
  
# Create a survival object 
surv_object <- Surv(time = as.numeric(customer_data$Order_Date), event = customer_data$Churn)  
  
# Fit Kaplan-Meier survival curve 
km_fit <- survfit(surv_object ~ 1, data = customer_data)  
  
# Plot the survival curve 
ggsurvplot(km_fit, data = customer_data, xlab = "Days", ylab = "Survival Probability", title = "Kaplan-Meier Survival Curve")
```

### Interpretation of the Kaplan-Meier Survival Curve

The Kaplan-Meier survival curve shown in the plot represents the survival probability over time, where "survival" in this context refers to the probability that a customer has not churned by a given time.

#### Kaplan-Meier Survival Curve:

**Plot Description:** - **X-axis (Days):** The number of days since the beginning of the observation period. - **Y-axis (Survival Probability):** The probability that a customer has not churned (remains a customer) at a given time. - **Curve:** The survival curve shows the estimated survival probability over time. The curve starts at 1 (or 100%) and decreases as customers churn over time. - **Strata Legend:** Indicates that all customers are considered together without stratification.

**Key Observations:** 1. **Initial Survival Probability:** - At the start (time = 0), the survival probability is 1, meaning all customers are active.

2.  **Survival over Time:**
    -   The curve remains flat at 1 for a significant portion of the time, indicating that customers did not churn during this period.
    -   Towards the end of the observation period (around 15,000 days), the curve starts to decline, indicating an increase in churn events.
3.  **Final Survival Probability:**
    -   The survival probability drops sharply at the end, reflecting a higher rate of churn as the time progresses towards the end of the observation period.
    -   This sharp decline might be due to the data structure, suggesting that many customers are recorded as having churned towards the end of the observation period.

**Interpretation:** - **Low Churn in Initial and Middle Periods:** The flat survival curve for most of the observation period suggests that customers tend to stay with the company for a long duration without churning. - **Increased Churn at the End:** The sharp decline towards the end indicates a significant increase in churn events, possibly due to the duration of the study or a specific time-related factor affecting customer retention. - **Overall Survival Probability:** The general shape of the curve suggests that the majority of the customers remain with the company until the end of the observation period.

**Practical Implications:** - **Retention Strategies:** Given the low churn in the initial and middle periods, efforts to retain customers should focus on understanding and mitigating the factors that lead to the increased churn towards the end. - **Further Analysis:** Investigate why churn rates increase towards the end of the observation period. This could involve looking at customer feedback, changes in service, market conditions, or other external factors. - **Targeted Interventions:** Develop targeted interventions for customers who are approaching the end of the observation period to prevent churn, based on the identified factors.

### Conclusion

The Kaplan-Meier survival curve provides a visual representation of customer retention over time, showing a high retention rate initially and a significant increase in churn towards the end. This information can be used to guide strategies aimed at improving customer retention and understanding the factors driving churn.
