---
title: "1.5 Hypothesis Testing & Statistical Analysis"
format: html
editor: visual
include-before: |
  <div style="text-align: center;">
    <img src="images/department_logo.png" width="169" />
    <img src="images/ioa_logo.png" width="122" />
    <img src="images/petra_logo.png" width="52" />
  </div>
---

## Hypothesis Testing

### Prepare Data, Fix Survey Data

-   Open survey data, rename columns, remove Arabic characters, change data types.

```{r}
library (dplyr)
library (readr)
library (readxl)
library (ggplot2)
library (stringr)
library(tidyr)

survey_data <- read_excel("data\\students_survey.xlsx")

colnames(survey_data) <- c("id","start_time","end_time","academic_year","gender","age","distance","course_name","course_branch","high_school_category","national_high_school_category","hight_school_average","study_hours","sleep_hours","mid_exam_score","gpa","does_work","fulltime_parttime","private_employed","satisfaction_at_university")

# Define a function to remove Arabic characters
remove_arabic <- function(x) {
  str_replace_all(x, "[\u0600-\u06FF]", "")
}

# Apply the function to all columns
survey_data <- survey_data %>%
  mutate(across(everything(), ~remove_arabic(as.character(.))))

# Replace empty strings with NA in all columns
survey_data <- survey_data %>%
  mutate(across(everything(), ~na_if(., "")))

survey_data <- survey_data %>% mutate(across(everything(), ~na_if(trimws(.), "")))


# Convert the columns to ordered factors
survey_data <- survey_data %>%
  mutate(
    private_employed = str_replace_all(private_employed,"Employed by others - ","employed"),
    private_employed = str_replace_all(private_employed,"Self employed -  
","private"),
    national_high_school_category = str_replace_all(national_high_school_category,"Adabi branch -","adabi"),
    national_high_school_category = str_replace_all(national_high_school_category,"Scientific Branch -","scientific"),
    course_branch = str_replace_all(course_branch,"Branch 1 -  1","1"),
    course_branch = str_replace_all(course_branch,"Branch 2 -  2","2"),
    distance = str_replace_all(distance,"5 -10 KM -  10  20","5-10km"),
    distance = str_replace_all(distance,"5 -10 KM -  5  10","5-10km"),
    distance = str_replace_all(distance,"Less than 5 KM -   5","<5km"),
    distance = str_replace_all(distance,"10 - 20 KM -  10  20","10-20km"),
    distance = str_replace_all(distance,"More than 20 KM -   20",">20km"),
    course_name = if_else(str_detect(course_name, "BI Methods and Models"), "BI Methods and Models", course_name),
    course_name = if_else(str_detect(course_name, "Descriptive Statistics for Business -   ;"), "Descriptive Statistics", course_name),
    course_name = str_replace_all(course_name,"Special Topics -  ;","Special Topics"),
    high_school_category = str_replace_all(high_school_category,"Jordanian Tawjihi -","Jordanian Tawjihi"),
    study_hours = if_else(study_hours == "5", "> 5", study_hours),
    study_hours = replace_na(study_hours, "< 1")
  )

# Clean numeric columns to ensure no non-numeric characters remain
clean_numeric <- function(x) {
  x <- str_replace_all(x, "[^0-9.]", "") # Remove non-numeric characters except '.'
  x[x == ""] <- NA                       # Replace empty strings with NA
  as.numeric(x)
}

# Convert char columns to numeric with cleaning
survey_data <- survey_data %>%
  mutate(
    age = clean_numeric(age),
    hight_school_average = clean_numeric(hight_school_average),
    gpa = clean_numeric(gpa),
    mid_exam_score = clean_numeric(mid_exam_score),
  )

# Convert the columns to ordered factors
survey_data <- survey_data %>%
  mutate(study_hours = factor(study_hours, levels = c("< 1", "1-3", "3-5", "> 5"), ordered = TRUE))

write.csv(survey_data,"data\\students_survey.csv",row.names = FALSE,  fileEncoding = "UTF-8")

str(survey_data)
```

**View the data**

```{r}
View(survey_data)
```

Explaining the statement **`dplyr::mutate(across(everything(), ~remove_arabic(as.character(.))))`** step by step:

### **`dplyr::mutate()`**

-   **`mutate()`** is a function from the **`dplyr`** package that is used to create or transform columns in a data frame.

-   It allows you to apply transformations to one or more columns and add the results as new columns or overwrite the existing ones.

### **`across(everything(), ...)`**

-   **`across()`** is a helper function that is used inside **`mutate()`** (and some other **`dplyr`** functions) to apply a function to multiple columns.

-   **`everything()`** is a selection helper from the **`dplyr`** package that selects all columns in the data frame. It means that the function specified inside **`across()`** will be applied to every column in the data frame.

### **`~remove_arabic(as.character(.))`**

-   The tilde **`~`** creates an anonymous function (a function without a name) that can be used inline.

-   **`remove_arabic`** is the function we defined to remove Arabic characters from a string.

-   **`as.character(.)`** converts the input (which will be each column in turn) to a character vector. The dot **`.`** represents the current column being processed.

-   **`remove_arabic(as.character(.))`** ensures that each column is treated as a character vector before applying the **`remove_arabic`** function to remove Arabic characters.

### **Putting it all together**

-   **`dplyr::mutate(across(everything(), ~remove_arabic(as.character(.))))`** modifies the data frame by applying the **`remove_arabic`** function to every column.

-   **`across(everything(), ~remove_arabic(as.character(.)))`** specifies that the transformation should be applied to all columns (**`everything()`**), and for each column, it will be converted to a character vector (**`as.character(.)`**) and then passed to the **`remove_arabic`** function.

-   The result of **`remove_arabic(as.character(.))`** is then used to replace the original column values in the data frame.

### 1. One-sample T-test

**Use:** To test if the mean of a single sample is significantly different from a known or hypothesized population mean.

**Assumptions:**

\- The sample data is normally distributed.

\- The sample observations are independent.

***Example:- Suppose we want to test if the average satisfaction score of customers for a new product is significantly different from the target satisfaction score of 5.***

**Experiment Design**

Conducting an experiment to test if the average satisfaction score of customers for a new product is significantly different from a target satisfaction score of 5 involves several scientific steps. Here’s a structured approach:

**Step 1: Define the Hypothesis**

-   **Null Hypothesis ((H_0))**: The mean satisfaction score is equal to 5.
-   **Alternative Hypothesis ((H_1))**: The mean satisfaction score is not equal to 5.

**Step 2: Design the Experiment**

1.  **Sample Size Determination**: Determine the appropriate sample size to ensure the results are statistically significant. This can be done using power analysis, considering the expected effect size, significance level (alpha), and power (1 - beta).

2.  **Random Sampling**: Select a random sample of customers to avoid bias. Ensure the sample is representative of the population.

3.  **Survey Design**: Create a standardized survey to measure customer satisfaction. Use a reliable and validated scale (e.g., Likert scale from 1 to 7).

4.  **Data Collection**: Administer the survey to the selected sample of customers after they have used the new product for a sufficient period.

**Step 3: Conduct the Experiment**

1.  **Administer the Survey**: Ensure that the data collection process is uniform and unbiased. Use online surveys, interviews, or physical questionnaires as appropriate.

2.  **Collect Data**: Gather the responses, ensuring data integrity and confidentiality.

**Step 4: Analyze the Data**

1.  **Descriptive Statistics**: Calculate the mean, median, standard deviation, and other relevant statistics of the collected data.

2.  **Check Assumptions**: Ensure the data meets the assumptions for a t-test (e.g., normally distributed data, independent samples).

3.  **Conduct the t-test**: Use statistical software (e.g., R) to perform a one-sample t-test to compare the sample mean to the target satisfaction score of 5.

**Step 5: Interpret the Results**

1.  **P-value and Test Statistic**: Evaluate the t-test result, focusing on the t-statistic and p-value.
    -   If the p-value is less than the significance level (usually 0.05), reject the null hypothesis.
    -   If the p-value is greater than the significance level, do not reject the null hypothesis.
2.  **Confidence Interval**: Examine the 95% confidence interval for the mean satisfaction score to understand the range in which the true mean lies.

**Step 6: Report the Findings**

1.  **Document the Process**: Describe the methodology, sample size, data collection process, and statistical analysis in detail.

2.  **Present the Results**: Use tables, graphs, and descriptive text to present the findings clearly. Highlight whether the average satisfaction score is significantly different from 5.

3.  **Draw Conclusions**: Summarize the findings and discuss the implications. If the null hypothesis is rejected, discuss potential reasons and next steps.

**Example: Test if the mean age of BI students = 21**

*Null Hypothesis: Mean age of BI students = 21*

*Alternative Hypothesis: Mean age of BI students ≠ 21*

```{r}
# Check the data to ensure there are no missing values and age is numeric
summary(survey_data$age)

# Perform one-sample t-test
t_test_result <- t.test(survey_data$age, mu = 22)

# Print the t-test result
print(t_test_result)
```

### Results:

-   **T-Test Statistic:** -1.7755
-   **P-Value:** 0.08156
-   **Mean Age:** 21.55556

### Interpretation:

**T-Test Statistic (-1.7755):**

This value represents how many standard deviations the sample mean is from the hypothesized population mean (22 years).

A larger absolute value of the t-statistic indicates a greater difference between the sample mean and the population mean under the null hypothesis.

**P-Value (0.08156):**

The p-value indicates the probability of obtaining a t-statistic at least as extreme as the one observed, assuming that the null hypothesis is true.

A p-value less than the significance level (commonly 0.05) leads to rejecting the null hypothesis.

In this case, the p-value is 0.08156, which is greater than 0.05, indicating that we do not reject the null hypothesis. This suggests that the mean age of the students is not significantly different from 22.

**Mean Age (21.55556):**

The average age of the students in the sample is approximately 21.56 years.

**Standard Deviation:**

(The standard deviation needs to be calculated or provided to complete this section)

### Conclusion:

Based on the results of the one-sample t-test, we do not reject the null hypothesis that the mean age of the students is 22. The mean age of the students is not significantly different from 22, with an average age of approximately 21.56 years.

### Visualize the mean students age

```{r}
ggplot(survey_data, aes(y = age)) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(title = "Boxplot of Age Distribution", y = "Age") +
      scale_y_continuous(breaks = seq(floor(min(survey_data$age, na.rm = TRUE)), ceiling(max(survey_data$age, na.rm = TRUE)), by = 0.5)) +
  theme_minimal()
```

### 2. Two-sample T-test (Independent)

**Use:** To compare the means of two independent samples to see if they are significantly different.

**Assumptions:**

\- The samples are independent of each other.

\- The data in each sample is normally distributed.

\- The variances of the two populations are equal (if using the standard t-test, not Welch's).

**Example 1: Compare the GPA of BI students by Gender**

*Null Hypothesis: There is no difference between the mean GPA for male and female BI students*

*Alternative Hypothesis: There is a difference between the mean GPA for male and female BI students*

```{r}
# Perform a two-sample t-test for GPA between genders
t_test_gpa_gender <- t.test(gpa ~ gender, data = survey_data)

# Print the result
print(t_test_gpa_gender)
```

### 

### Interpretation:

-   **T-Test Statistic:** -0.17232
-   **P-Value:** 0.8639
-   **Mean GPA in Group Female:** 2.731724
-   **Mean GPA in Group Male:** 2.755200
-   **95% Confidence Interval:** -0.2968477 to 0.2498960

**T-Test Statistic (-0.17232):** This value indicates the number of standard deviations the difference in sample means is from the hypothesized difference in population means (which is 0 under the null hypothesis).

**P-Value (0.8639):** The p-value indicates the probability of obtaining a t-statistic at least as extreme as the one observed, assuming that the null hypothesis is true. A p-value greater than the significance level (commonly 0.05) means we fail to reject the null hypothesis.

In this case, the p-value is 0.8639, which is much greater than 0.05, indicating that we do not reject the null hypothesis. This suggests that there is no significant difference in GPA between female and male students.

**Mean GPA:** - Female: 2.731724 - Male: 2.755200

The average GPAs are very close, supporting the result that there is no significant difference between the two groups.

### Conclusion:

Based on the results of the Welch Two Sample t-test, we do not reject the null hypothesis that there is no difference in mean GPA between female and male students. The mean GPA of female students is approximately 2.73, and the mean GPA of male students is approximately 2.76, with no significant difference between the two groups.

### Visualize GPA by Gender:

To create a boxplot showing the GPA distribution by gender, use the following R code:

```{r}
library(ggplot2)

# Create a boxplot for GPA distribution by gender
ggplot(survey_data, aes(x = gender, y = gpa, fill = gender)) +
  geom_boxplot() +
  labs(title = "Boxplot of GPA Distribution by Gender", x = "Gender", y = "GPA") +
  scale_y_continuous(breaks = seq(floor(min(survey_data$gpa, na.rm = TRUE)), ceiling(max(survey_data$gpa, na.rm = TRUE)), by = 0.2)) +
  theme_minimal()
```

**Example 2: Test if having a job has influence on Student's GPA**

```{r}
# Perform a two-sample t-test for GPA between work status
t_test_gpa_work <- t.test(gpa ~ does_work, data = survey_data)

# Print the result
print(t_test_gpa_work)
```

### Interpretation:

-   **T-Test Statistic:** 0.10266
-   **P-Value:** 0.9187
-   **Mean GPA in Group No:** 2.748710
-   **Mean GPA in Group Yes:** 2.734348
-   **95% Confidence Interval:** -0.2671799 to 0.2959036

**T-Test Statistic (0.10266):** This value indicates the number of standard deviations the difference in sample means is from the hypothesized difference in population means (which is 0 under the null hypothesis).

**P-Value (0.9187):** The p-value indicates the probability of obtaining a t-statistic at least as extreme as the one observed, assuming that the null hypothesis is true. A p-value greater than the significance level (commonly 0.05) means we fail to reject the null hypothesis.

In this case, the p-value is 0.9187, which is much greater than 0.05, indicating that we do not reject the null hypothesis. This suggests that there is no significant difference in GPA between students who do work and those who do not.

**Mean GPA:** - Group No: 2.748710 - Group Yes: 2.734348

The average GPAs are very close, supporting the result that there is no significant difference between the two groups.

### Conclusion:

Based on the results of the Welch Two Sample t-test, we do not reject the null hypothesis that there is no difference in mean GPA between students who do work and those who do not. The mean GPA of students who do not work is approximately 2.75, and the mean GPA of students who do work is approximately 2.73, with no significant difference between the two groups.

### Visualize GPA by Work Status:

To create a boxplot showing the GPA distribution by work status, use the following R code:

```{r}
library(ggplot2)

# Create a boxplot for GPA distribution by work status
ggplot(survey_data, aes(x = does_work, y = gpa, fill = does_work)) +
  geom_boxplot() +
  labs(title = "Boxplot of GPA Distribution by Work Status", x = "Work Status", y = "GPA") +
  scale_y_continuous(breaks = seq(floor(min(survey_data$gpa, na.rm = TRUE)), ceiling(max(survey_data$gpa, na.rm = TRUE)), by = 0.2)) +
  theme_minimal()
```

**Example 3: Compare the GPA of Adabi Tawjihi Branch and Scientifc Tawjihi Branch**

```{r}
# Filter the data for the two branches
filtered_data <- survey_data %>%
  filter(national_high_school_category %in% c("adabi", "scientific"))

# Perform a two-sample t-test for GPA between Adabi branch and Scientific branch
t_test_result <- t.test(gpa ~ national_high_school_category, data = filtered_data)

# Print the result
print(t_test_result)
```

### Interpretation:

-   **T-Test Statistic:** -0.8071
-   **P-Value:** 0.4251
-   **Mean GPA in Group Adabi:** 2.699444
-   **Mean GPA in Group Scientific:** 2.813750
-   **95% Confidence Interval:** -0.4019184 to 0.1733073

**T-Test Statistic (-0.8071):** This value represents how many standard deviations the difference in sample means is from the hypothesized difference in population means (which is 0 under the null hypothesis).

**P-Value (0.4251):** The p-value indicates the probability of obtaining a t-statistic at least as extreme as the one observed, assuming that the null hypothesis is true. A p-value greater than the significance level (commonly 0.05) means we fail to reject the null hypothesis.

In this case, the p-value is 0.4251, which is greater than 0.05, indicating that we do not reject the null hypothesis. This suggests that there is no significant difference in GPA between students from the Adabi and Scientific high school categories.

**Mean GPA:** - Group Adabi: 2.699444 - Group Scientific: 2.813750

The average GPAs are relatively close, supporting the result that there is no significant difference between the two groups.

### Conclusion:

Based on the results of the Welch Two Sample t-test, we do not reject the null hypothesis that there is no difference in mean GPA between students from the Adabi and Scientific high school categories. The mean GPA of students from the Adabi category is approximately 2.70, and the mean GPA of students from the Scientific category is approximately 2.81, with no significant difference between the two groups.

### Visualize GPA by High School Category:

```{r}
library(ggplot2)

# Create a boxplot for GPA distribution by high school category
ggplot(survey_data, aes(x = national_high_school_category, y = gpa, fill = national_high_school_category)) +
  geom_boxplot() +
  labs(title = "Boxplot of GPA Distribution by High School Category", x = "High School Category", y = "GPA") +
  scale_y_continuous(breaks = seq(floor(min(survey_data$gpa, na.rm = TRUE)), ceiling(max(survey_data$gpa, na.rm = TRUE)), by = 0.2)) +
  theme_minimal()
```

**Plotting the relation**

```{r}
# Calculate the sample size for each category
sample_sizes <- survey_data %>%
  group_by(national_high_school_category) %>%
  summarise(count = n())

# Create a bar chart
ggplot(survey_data, aes(x = national_high_school_category)) +
  geom_bar(fill = "skyblue", color = "black") +
  geom_text(data = sample_sizes, aes(x = national_high_school_category, y = count + 1, label = count), 
            vjust = -0.5, size = 5) +
  ggtitle("Number of Students in Adabi and Scientific Branches") +
  xlab("National High School Category") +
  ylab("Count of Students") +
  theme_minimal() +
  ylim(0, max(sample_sizes$count) + 5)  # Increase the upper limit of y-axis


# Create boxplot to visualize the relationship between study hours and GPA
ggplot(survey_data, aes(x = national_high_school_category, y = gpa)) +
 geom_boxplot() +
  ggtitle("GPA Distribution by National High School Category") +
  xlab("National High School Category") +
  ylab("GPA") +
  scale_y_continuous(breaks = seq(1, 4, by = 0.2)) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  geom_text(data = sample_sizes, aes(x = national_high_school_category, y = 4, label = paste0("sample size=", count)), position = position_dodge(width = 0.75), vjust = 1, size = 3)

```

**Adjusting the y-coordinate**:

-   **`aes(x = national_high_school_category, y = count + 1, label = count)`**: This moves the text labels slightly above the top of the bars by adding 1 to the count.

**Setting the y-axis limit**:

-   **`ylim(0, max(sample_sizes$count) + 5)`**: This increases the upper limit of the y-axis to ensure there is enough space above the bars for the text labels.

### 3. Paired Sample T-test

**Use:** To compare the means of two related samples (e.g., before and after measurements on the same subjects).

**Assumptions:** - The differences between the paired observations are normally distributed. - The pairs are independent of each other.

***Example:- Suppose we want to test if a training program has significantly improved employee productivity scores by comparing their productivity before and after the training.***

**Code:**

```{r}
# Set seed for reproducibility
set.seed(123)

# Generate productivity scores before and after the training
productivity_before <- rnorm(30, mean = 5, sd = 2)  # Productivity scores before training
productivity_after <- productivity_before + rnorm(30, mean = 0.5, sd = 1)  # Productivity scores after training

# Perform paired sample t-test to compare the mean productivity scores before and after training
t_test_result <- t.test(productivity_before, productivity_after, paired = TRUE)

# Print the productivity scores
print(productivity_before)
print(productivity_after)

# Print the t-test result
print(t_test_result)
```

**Interpretation:**

-   **Productivity Scores:**

    -   **Before Training:** Generated productivity scores with a mean of approximately 5.

    -   **After Training:** Generated productivity scores that are on average higher than before training.

-   **T-test Result:**

    -   **t:** Test statistic (-4.4489)

    -   **df:** Degrees of freedom (29)

    -   **p-value:** Probability of observing the data if the null hypothesis is true (0.0001169)

    -   **95% Confidence Interval:** Range within which the true mean difference lies with 95% confidence (-0.9901802 to -0.3664964=)

    -   **Mean of the Differences:** Average difference in productivity scores before and after training (-0.6783383)

**Conclusion:** Since the p-value (0.0001169) is less than the common significance level (0.05), we reject the null hypothesis.

This indicates that there is a significant difference in productivity scores before and after the training, with productivity increasing after the training program.

### 4. One-way ANOVA

**Use:** To compare the means of three or more groups to see if at least one mean is different.

**Assumptions:**

\- The data in each group is normally distributed.

\- The variances of the populations are equal (homogeneity of variances).

\- The samples are independent.

***Example 1:-*** **Test if there is a difference in student GPA according to study hours**

To perform an ANOVA test to compare the effect of study hours on GPA, we first need to ensure that the study hours are categorized (e.g., "less than 1 hour," "1-3 hours," etc.) into factors. Then, wecan use the `aov` function to perform the ANOVA test in R.

### R Code for ANOVA Test Comparing Study Hours with GPA

```{r}
# Define the levels in the desired order
study_hours_levels <- c("Less than 1 hour", "1-3 hours", "3-5 Hours", "More than 5 hours")

# Convert study_hours to an ordered factor
survey_data$study_hours <- factor(survey_data$study_hours, levels = study_hours_levels, ordered = TRUE)

# Check the levels to confirm the order
#levels(survey_data$study_hours)
#summary(survey_data$study_hours)

# Perform ANOVA test
anova_result <- aov(gpa ~ study_hours, data = survey_data)

# Print the summary of the ANOVA test
print(summary(anova_result))
```

### Explanation:

Based on the ANOVA results, there is no significant effect of study hours on GPA. The p-value of 0.993 indicates that the differences in mean GPA among the study hours groups are not statistically significant. This suggests that, in this dataset, the amount of time spent studying does not have a meaningful impact on GPA.

### **Possible Reasons for No Significant Effect:**

1.  **Sample Size**:

    -   The sample sizes, especially for the "More than 5 Hours" category, are small. Small sample sizes can lead to less reliable statistical results.

2.  **Other Influencing Factors**:

    -   GPA may be influenced by many other factors beyond just study hours, such as the effectiveness of study methods, prior knowledge, teaching quality, etc.

3.  **Homogeneity of Study Habits**:

    -   There might be homogeneity in the study habits of students in this dataset, meaning most students have similar study patterns, leading to similar GPAs.

4.  **Measurement of Study Hours**:

    -   The accuracy of self-reported study hours can be variable. Students may not accurately report their study hours, leading to less precise groupings.

### Visualize GPA by Study Hours

```{r}
# Load necessary library for visualization
library(ggplot2)

# Calculate the sample size for each category
sample_sizes <- survey_data %>%
  group_by(study_hours) %>%
  summarise(count = n())

# Create boxplot to visualize the relationship between study hours and GPA
ggplot(survey_data, aes(x = study_hours, y = gpa)) +
  geom_boxplot() +
  ggtitle("Boxplot of GPA by Study Hours") +
  xlab("Study Hours") +
  ylab("GPA") +
  scale_y_continuous(breaks = seq(1, 4, by = 0.2)) +
  scale_fill_brewer(palette = "Set3") +
  theme_minimal() +
  geom_text(data = sample_sizes, aes(x = study_hours, y = 4, label = paste0("sample size=", count)), position = position_dodge(width = 0.75), vjust = 1, size = 3)
```

-   **`sample_sizes <- survey_data %>% group_by(study_hours) %>% summarise(count = n())`** calculates the sample size for each **`study_hours`** category.

-   **`geom_text()`** adds the sample size labels to the plot. The labels are positioned just above the top of the plot (y = 4) and are adjusted to avoid overlap using **`position_dodge`** and **`vjust`**.

***Example 2:- Test if there is a difference in student GPA according to the high school certificate category (National, SAT/ACT, IG, IB)***

```{r}
# Convert high_school_category to a factor if it is not already
survey_data$high_school_category <- as.factor(survey_data$high_school_category)

# Perform ANOVA to test the relationship between high school category and GPA
anova_result <- aov(gpa ~ high_school_category, data = survey_data)

# Print the summary of the ANOVA test
summary(anova_result)
```

### Interpretation of ANOVA Results

The ANOVA table helps determine if there is a significant relationship between the `high_school_category` and `GPA`. Here are the results:

**ANOVA Table**:

```         
                          Df  Sum Sq Mean Sq F value Pr(>F)
high_school_category      3  0.196 0.06524   0.239  0.869
Residuals                43 11.762 0.27354
```

### Explanation:

1.  **Degrees of Freedom (Df)**:
    -   **high_school_category**: 3 (number of categories minus 1).
    -   **Residuals**: 43 (total number of observations minus the number of categories).
2.  **Sum of Squares (Sum Sq)**:
    -   **high_school_category**: 0.196
    -   **Residuals**: 11.762
3.  **Mean Squares (Mean Sq)**:
    -   **high_school_category**: 0.06524 (Sum Sq / Df)
    -   **Residuals**: 0.27354 (Sum Sq / Df)
4.  **F value**:
    -   The F value is 0.239, calculated as the ratio of the mean square for `high_school_category` to the mean square for the residuals (0.06524 / 0.27354).
5.  **p-value (Pr(\>F))**:
    -   The p-value is 0.869, indicating the probability of observing an F value at least as extreme as 0.239 under the null hypothesis (that there is no difference in GPA between the high school categories).

### Conclusion:

Since the p-value (0.869) is much greater than the common significance level of 0.05, we fail to reject the null hypothesis. This suggests that there is no statistically significant difference in GPA between the different high school categories. In other words, the high school category does not appear to have a significant impact on GPA in this dataset.

### Visualization:

To complement the statistical results, you can create a box plot to visualize the GPA distribution across different high school categories:

```{r}
# Calculate the sample size for each category
sample_sizes <- survey_data %>%
  group_by(high_school_category) %>%
  summarise(count = n())

# Create a box plot to visualize the relationship between high school category and GPA
ggplot(survey_data, aes(x = high_school_category, y = gpa, fill = high_school_category)) +
  geom_boxplot() +
  ggtitle("GPA Distribution by High School Category") +
  xlab("High School Category") +
  ylab("GPA") +
    scale_y_continuous(breaks = seq(1, 4, by = 0.2)) +
  scale_fill_brewer(palette = "Set2") +
  theme_minimal() +
  geom_text(data = sample_sizes, aes(x = high_school_category, y = 4, label = paste0("sample size=", count)), position = position_dodge(width = 0.75), vjust = 1, size = 3)
```

### Explanation of the Box Plot Code:

1.  **Loading Libraries**:
    -   `library(dplyr)` for data manipulation.
    -   `library(ggplot2)` for visualization.
    -   `library(readxl)` for reading Excel files.
2.  **Loading Data**:
    -   `read_excel("students_survey.xlsx")` loads the Excel file into an R data frame.
3.  **Convert High School Category to Factor**:
    -   Ensure the `national_high_school_category` column is a factor using `as.factor`.
4.  **Create Box Plot**:
    -   `geom_boxplot()` creates the box plot to visualize the distribution of GPA for each high school category.
    -   `scale_fill_brewer(palette = "Set3")` applies a color palette.
    -   `ggtitle`, `xlab`, and `ylab` add the title and axis labels.
    -   `theme_minimal()` provides a clean and minimalistic theme for the plot.

### Running the Code:

1.  Copy the box plot code.
2.  Open RStudio or any R environment.
3.  Paste the code into the R script editor.
4.  Run the script.

This will generate a box plot showing the GPA distribution for each high school category, providing a visual representation to complement the ANOVA results. If you need further assistance or additional customizations, feel free to ask!

### 5. Chi-square Test for Independence

**Use:** To test if there is a significant association between two categorical variables.

**Assumptions:** - The data is in the form of counts or frequencies. - The observations are independent. - The expected frequency in each cell of the contingency table is at least 5.

***Example:- Suppose we want to test if there is a significant association between the type of marketing campaign (Email vs. Social Media) and customer response (Purchased vs. Not Purchased).***

**Code:**

```{r}

# Create a contingency table for gender and work status
contingency_table <- table(survey_data$gender, survey_data$does_work)

# Print the contingency table
print(contingency_table)

# Perform the Chi-Square test of independence
chi_square_test <- chisq.test(contingency_table)

# Print the result
print(chi_square_test)

```

### Interpretation of the Chi-Square Test Results:

The Chi-Square test of independence results indicate whether there is a significant relationship between gender and work status.

**Contingency Table**:

```         
         No  Yes
Female   20    6
Male      9   12
```

**Chi-Square Test Results**: - **X-squared**: 4.3545 - **Degrees of Freedom (df)**: 1 - **p-value**: 0.03691

### Explanation:

1.  **Contingency Table**:
    -   The table shows the counts of individuals by gender and whether they work or not.
    -   For example, there are 20 females who do not work and 6 females who do work.
2.  **Chi-Square Statistic (X-squared = 4.3545)**:
    -   The Chi-Square statistic measures the discrepancy between the observed counts and the counts expected if there were no relationship between gender and work status.
3.  **Degrees of Freedom (df = 1)**:
    -   Degrees of freedom for a Chi-Square test of independence is calculated as (number of rows - 1) \* (number of columns - 1). In this case, (2 - 1) \* (2 - 1) = 1.
4.  **p-value (0.03691)**:
    -   The p-value indicates the probability of observing a Chi-Square statistic as extreme as, or more extreme than, the observed value under the null hypothesis (no relationship between gender and work status).
    -   A p-value less than 0.05 typically indicates that we reject the null hypothesis. In this case, the p-value is 0.03691, which is less than 0.05.

### Conclusion:

Since the p-value (0.03691) is less than the significance level of 0.05, we reject the null hypothesis. This suggests that there is a statistically significant relationship between gender and work status. Specifically, the data indicates that the distribution of work status (whether a student works or not) is significantly different between males and females.

### Visualization (Optional):

We can also create a bar plot to visualize the relationship between gender and work status:

```{r}
# Create a bar plot to visualize the relationship between gender and work status
ggplot(survey_data, aes(x = gender, fill = does_work)) +
  geom_bar(position = "dodge") +
  ggtitle("Work Status by Gender") +
  xlab("Gender") +
  ylab("Count of Students") +
  scale_fill_brewer(palette = "Set2", name = "Work Status") +
  theme_minimal()
```

This plot will help visualize the counts of students by gender and work status, providing a clear picture of the relationship between these two variables.

------------------------------------------------------------------------

## Statistical Analysis

### 1. Correlation Analysis

#### Introduction:

Correlation analysis measures the strength and direction of the relationship between two variables.

For instance, we can analyze the correlation between hjigh school average and GPA.

#### R Code:

```{r}
# Remove rows with NA values in the relevant columns
filtered_data <- survey_data %>%
  filter(!is.na(hight_school_average) & !is.na(gpa))

# Calculate the Pearson correlation coefficient
correlation_result <- cor.test(filtered_data$hight_school_average, filtered_data$gpa)

# Print the result
print(correlation_result)

# Create the scatter plot
ggplot(filtered_data, aes(x = hight_school_average, y = gpa)) +
  geom_point(color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  ggtitle("Scatter Plot of Tawjihi Average vs GPA") +
  xlab("Tawjihi Average (High School Average)") +
  ylab("GPA") +
  theme_minimal()
```

### Results of the Correlation Test Between Tawjihi Average and GPA

**Pearson Correlation Coefficient**: 0.2628\
**P-Value**: 0.0811

### Interpretation:

1.  **Pearson Correlation Coefficient (0.2628)**:
    -   The Pearson correlation coefficient measures the strength and direction of the linear relationship between two variables.
    -   A value of 0.2628 indicates a weak positive correlation between Tawjihi average and GPA. This suggests that as the Tawjihi average increases, GPA tends to increase slightly as well.
2.  **P-Value (0.0811)**:
    -   The p-value indicates the probability that the observed correlation occurred by chance if there is no actual correlation in the population.
    -   In this case, the p-value is 0.0811, which is slightly above the common significance level of 0.05. Therefore, we do not have strong evidence to reject the null hypothesis of no correlation. This suggests that the observed correlation is not statistically significant at the 5% level.

### Conclusion:

Based on the results of the Pearson correlation test, there is a weak positive correlation between Tawjihi average and GPA. However, this correlation is not statistically significant at the 5% level. Therefore, while there is a slight tendency for higher Tawjihi averages to be associated with higher GPAs, this relationship is not strong or statistically significant in this dataset.

### 2. Regression Analysis: Linear Regression Example using `mtcars` Dataset

#### Introduction:

-   Linear regression models the relationship between a dependent variable and one or more independent variables. In this example, we will use the `mtcars` dataset to predict miles per gallon (mpg) based on horsepower (hp) and weight (wt).

#### R Code:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2)

# Fit a linear regression model to predict mpg based on hp and wt
regression_model <- lm(mpg ~ hp + wt, data = mtcars)  
# Summarize the regression model 
summary(regression_model)  

# Plot the regression results 
ggplot(mtcars, aes(x = hp, y = mpg)) +   
  geom_point() +   
  geom_smooth(method = "lm") +   
  labs(title = "Linear Regression: MPG vs. HP", x = "Horsepower (hp)", y = "Miles per Gallon (mpg)")
```

The results of the linear regression and the corresponding plot can be interpreted as follows:

#### Regression Results:

**Model Summary:**

**Residuals:**

The distribution of residuals provides insights into the model's fit. The range shows some variation, indicating potential outliers.

**Coefficients:**

**Intercept:**

-   Estimate: 37.227
-   Std. Error: 1.598
-   t value: 23.296
-   Pr(\>\|t\|): \< 2e-16 (highly significant)

**Horsepower (hp):**

-   Estimate: -0.031
-   Std. Error: 0.009
-   t value: -3.520
-   Pr(\>\|t\|): 0.00145 (significant)

**Weight (wt):**

-   Estimate: -3.877
-   Std. Error: 0.632
-   t value: -6.138
-   Pr(\>\|t\|): 1.12e-06 (highly significant)

**Significance Codes:**

The significance codes indicate the level of significance for each predictor.

Both horsepower and weight are significant predictors of miles per gallon (mpg) (p-values \< 0.01).

**Model Fit:**

-   Residual standard error: 2.593 on 29 degrees of freedom
-   Multiple R-squared: 0.8264
-   Adjusted R-squared: 0.8148
-   F-statistic: 71.41 on 2 and 29 DF
-   p-value: \< 2.2e-16 (highly significant overall model)

#### Interpretation:

**Intercept:**

The intercept of 37.227 suggests that when both horsepower and weight are zero, the expected miles per gallon is 37.227.

**Horsepower (hp):**

The coefficient for horsepower is -0.031. This indicates that for each unit increase in horsepower, mpg decreases by approximately 0.031 units, holding weight constant. The negative coefficient and significant p-value suggest a strong inverse relationship between horsepower and mpg.

**Weight (wt):**

The coefficient for weight is -3.877. This indicates that for each additional unit of weight, mpg decreases by approximately 3.877 units, holding horsepower constant. The negative coefficient and highly significant p-value suggest a strong inverse relationship between weight and mpg.

**Model Fit:**

The Multiple R-squared value of 0.8264 indicates that approximately 82.64% of the variability in mpg is explained by the model. This is relatively high, suggesting that the model is a good fit.

The F-statistic and its p-value indicate that the overall model is significant, meaning at least one of the predictors (horsepower or weight) significantly contributes to the model.

#### Plot Interpretation:

The plot of mpg vs. horsepower with a linear regression line (using `geom_smooth()`) provides a visual representation of the relationship between mpg and horsepower. The line slopes downward, indicating an inverse relationship.

#### Conclusion:

The regression analysis shows that both horsepower and weight are significant predictors of mpg. Higher horsepower and weight have a negative impact on mpg. The model explains a significant portion of the variability in mpg, indicating that these factors play a substantial role in determining miles per gallon.

### 3. Logistic Regression Example using `mtcars` Dataset

#### Introduction:

-   Logistic regression models the relationship between a binary dependent variable and one or more independent variables. In this example, we will use the `mtcars` dataset to predict the likelihood of a car having an automatic (am = 0) or manual (am = 1) transmission based on horsepower (hp) and weight (wt).

#### R Code:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2)
library(caret)  # For confusion matrix
library(pROC)   # For AUC

# Convert 'am' to a factor for logistic regression
mtcars$am <- as.factor(mtcars$am)

# Fit a logistic regression model to predict transmission based on hp and wt
logistic_model <- glm(am ~ hp + wt, data = mtcars, family = binomial)  
# Summarize the logistic regression model 
summary(logistic_model)  

# Make predictions on the training set
predicted_probabilities <- predict(logistic_model, type = "response")
predicted_classes <- ifelse(predicted_probabilities > 0.5, "1", "0")

# Confusion Matrix
conf_matrix <- confusionMatrix(factor(predicted_classes), mtcars$am)
print(conf_matrix)

# Accuracy
accuracy <- conf_matrix$overall['Accuracy']
print(paste("Accuracy:", accuracy))

# ROC Curve and AUC
roc_curve <- roc(mtcars$am, predicted_probabilities)
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))

# Plot ROC Curve
plot(roc_curve, col = "blue", main = "ROC Curve")
```

The results of the logistic regression and the corresponding evaluations can be interpreted as follows:

#### Logistic Regression Results:

**Model Summary:**

**Coefficients:**

**Intercept:**

-   Estimate: 18.86630
-   Std. Error: 7.44356
-   z value: 2.535
-   Pr(\>\|z\|): 0.01126 (significant)

**Horsepower (hp):**

-   Estimate: 0.03626
-   Std. Error: 0.01773
-   z value: 2.044
-   Pr(\>\|z\|): 0.04091 (significant)

**Weight (wt):**

-   Estimate: -8.08348
-   Std. Error: 3.06868
-   z value: -2.634
-   Pr(\>\|z\|): 0.00843 (highly significant)

**Significance Codes:**

The significance codes indicate the level of significance for each predictor.

Both horsepower and weight are significant predictors of transmission type (p-values \< 0.05).

#### Evaluation Metrics:

**Confusion Matrix:** - The confusion matrix provides a summary of prediction results on a classification problem. It shows the number of correct and incorrect predictions broken down by each class.

**Accuracy:** - Accuracy is the proportion of true results (both true positives and true negatives) among the total number of cases examined. It provides an overall measure of the model's predictive power.

**ROC Curve and AUC:** - The ROC (Receiver Operating Characteristic) curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system. The AUC (Area Under the Curve) measures the entire two-dimensional area underneath the entire ROC curve. A higher AUC indicates better model performance.

#### Example Results Interpretation:

Suppose the confusion matrix, accuracy, and AUC results are as follows:

**Confusion Matrix:**

```         
          Reference
Prediction  0  1
        0 10  2
        1  1 19
```

**Accuracy:**

```         
Accuracy: 0.935
```

**AUC:**

```         
AUC: 0.965
```

**Interpretation:**

-   **Confusion Matrix:**
    -   True Negatives (TN): 10
    -   False Positives (FP): 1
    -   False Negatives (FN): 2
    -   True Positives (TP): 19
-   **Accuracy:**
    -   The model correctly predicts the transmission type 93.5% of the time.
-   **AUC:**
    -   An AUC of 0.965 indicates excellent model performance, meaning the model has a high ability to distinguish between the two classes (automatic vs. manual transmission).

These metrics provide a comprehensive evaluation of the logistic regression model's performance, helping to understand its predictive power and reliability.

### 4. Clustering: K-Means Clustering Example

#### Introduction:

K-means clustering partitions the data into k clusters, where each data point belongs to the cluster with the nearest mean. This technique can be used to group customers based on purchasing behavior.

#### R Code:

```{r}
# Install necessary packages
if (!requireNamespace("factoextra", quietly = TRUE)) {
  install.packages("factoextra")
}

# Load necessary libraries
library(dplyr)
library(readr)
library(ggplot2)
library(cluster)
library(factoextra)

# Load the dataset
superstore <- read_csv("data\\superstore.csv")

# Select relevant columns and scale the data   
customer_data <- superstore %>% group_by(`Customer ID`) %>%  
  summarise(Total_Sales = sum(Sales), Total_Orders = n()) %>%   
  ungroup()

scaled_data <- scale(customer_data %>% select(Total_Sales, Total_Orders))

# Perform k-means clustering with 3 clusters  
set.seed(123) 
kmeans_result <- kmeans(scaled_data, centers = 3, nstart = 25)

# Add cluster assignment to the original data  
customer_data$Cluster <- as.factor(kmeans_result$cluster)

# Visualize the clusters  
ggplot(customer_data, aes(x = Total_Sales, y = Total_Orders, color = Cluster)) +  
  geom_point() + 
  labs(title = "K-Means Clustering: Customers", x = "Total Sales", y = "Total Orders")

# Evaluate the clustering using silhouette analysis
silhouette_score <- silhouette(kmeans_result$cluster, dist(scaled_data))

# Plot silhouette analysis with improved clarity using fviz_silhouette
fviz_silhouette(silhouette_score) +
  labs(title = "Silhouette Plot for K-Means Clustering") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

The results of the K-means clustering and the corresponding plots can be interpreted as follows:

### K-Means Clustering Results:

**Cluster Centers:**

```{r}
print(kmeans_result$centers)
```

The cluster centers provide the mean values of each feature for the clusters.

**Within-cluster Sum of Squares:**

```{r}
print(kmeans_result$tot.withinss)
```

This value indicates how tightly the clusters are packed. Lower values suggest better-defined clusters.

### Evaluation Metrics:

**Silhouette Analysis:** To evaluate the clustering performance, we use silhouette analysis, which measures how similar each data point is to its own cluster compared to other clusters.

```{r}
# Compute the silhouette width for each data point
silhouette_width <- silhouette(kmeans_result$cluster, dist(scaled_data))

# Plot silhouette analysis
plot(silhouette_width, main = "Silhouette Plot for K-Means Clustering")
```

**Silhouette Plot:** The silhouette plot provides a visual representation of the silhouette width for each data point. Values near 1 indicate that the data points are well clustered, values near 0 indicate that the data points are on or very close to the decision boundary between two neighboring clusters, and negative values indicate that those data points might have been assigned to the wrong cluster.

### Interpretation:

**Clusters:**

**Cluster 1 (Red):** - Customers in this cluster tend to have higher total sales, with values ranging from approximately 5,000 to 25,000. The number of orders for these customers varies widely but tends to be higher on average, often above 15 orders.

**Cluster 2 (Green):** - This cluster represents customers with relatively low total sales (up to around 5,000) and a smaller number of total orders (generally less than 10 orders). These customers represent the lower sales and lower order frequency segment.

**Cluster 3 (Blue):** - Customers in this cluster fall between the other two clusters in terms of total sales (up to around 10,000) and have a moderate number of total orders, typically ranging between 10 and 20 orders.

**Cluster Characteristics:**

-   **Cluster 1:** High-value customers who make significant purchases (high total sales) and place many orders. These might be your most valuable customers in terms of revenue.
-   **Cluster 2:** Lower-value customers who contribute less to total sales and place fewer orders. These customers may represent occasional buyers or those with low engagement.
-   **Cluster 3:** Medium-value customers who have moderate sales and order frequency. These customers are likely moderately engaged and contribute a significant, but not the highest, portion of sales.

**Business Implications:**

**Targeting and Marketing:**

-   **Cluster 1:** These high-value customers should be prioritized for loyalty programs, special offers, and personalized marketing to retain and further engage them.
-   **Cluster 2:** Efforts might be made to convert these low-value customers into higher-value ones, perhaps through targeted promotions or incentives to increase their purchase frequency and order size.
-   **Cluster 3:** These medium-value customers could benefit from strategies aimed at boosting their engagement and moving them into the high-value cluster.

**Visualization Insights:**

-   The clear separation between clusters suggests that the K-means algorithm has effectively grouped customers based on their sales and ordering behavior.
-   The distribution of points within each cluster provides a visual indication of the variability in customer behavior within each segment.

**Silhouette Analysis:**

-   The silhouette plot shows that most data points have a high silhouette width, indicating well-defined clusters.
-   Cluster 3 has the highest average silhouette width of 0.54, suggesting it is the best-defined cluster.
-   Cluster 2 has the lowest average silhouette width of 0.22, indicating some points may be misclassified or lie between clusters.
-   A high average silhouette width of 0.44 suggests that the clustering structure is appropriate.

### Conclusion:

The K-means clustering analysis has segmented customers into three distinct groups based on their total sales and total orders. Each cluster represents a different level of customer value and engagement, providing insights that can guide targeted marketing strategies, customer relationship management, and business decision-making to optimize sales and customer satisfaction. The silhouette analysis confirms that the clustering structure is well-defined and appropriate.

### 5. Principal Component Analysis (PCA)

**Introduction**: - Principal Component Analysis (PCA) reduces the dimensionality of our dataset while preserving as much variability as possible, which can help in visualizing high-dimensional data.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(FactoMineR)
library(factoextra)  

# Select numeric columns for PCA 
numeric_data <- superstore %>%  select(Sales, Profit, Discount, Quantity)  

# Perform PCA 
pca_result <- PCA(numeric_data, graph = FALSE)  

# Visualize PCA 
fviz_pca_var(pca_result, col.var = "contrib", gradient.cols = c("blue", "red"))
```

The image displays the results of a Principal Component Analysis (PCA) on selected numeric columns (`Sales`, `Profit`, `Discount`, `Quantity`) from the dataset.

Here is the interpretation of the PCA plot:

### Interpretation of the PCA Plot:

1.  **Principal Components (Dimensions)**:
    -   **Dim1 (PC1)**: The first principal component, which explains 39.7% of the variance in the data.
    -   **Dim2 (PC2)**: The second principal component, which explains 26.5% of the variance in the data.
    -   Together, these two components explain a significant portion (66.2%) of the total variance in the data, indicating that PCA has effectively reduced the dimensionality while retaining most of the variability.
2.  **Variable Contributions**:
    -   **Sales** and **Profit** have strong positive loadings on Dim1, suggesting that they are positively correlated and contribute similarly to this principal component.
    -   **Discount** has a strong negative loading on Dim1, indicating that it is inversely related to Sales and Profit.
    -   **Quantity** has a positive loading on Dim2, suggesting it is primarily explained by this second component.
3.  **Correlation and Relationships**:
    -   The length and direction of the arrows represent the strength and direction of the correlation between the variables and the principal components.
    -   **Sales** and **Profit** arrows point in the same direction, indicating a strong positive correlation.
    -   **Discount** points in the opposite direction to **Sales** and **Profit**, indicating an inverse relationship with these variables.
    -   **Quantity** points in a different direction, indicating it has a distinct contribution to the variance explained by Dim2.
4.  **Color Gradient (Contribution)**:
    -   The color gradient from blue to red indicates the contribution of each variable to the principal components. Variables with darker red arrows contribute more to the principal components.

### Insights from the PCA:

1.  **Dimension 1 (Dim1)**:
    -   Captures the trade-off between high Sales and Profit versus high Discounts.
    -   A high score on Dim1 indicates higher Sales and Profit and lower Discount, while a low score indicates the opposite.
2.  **Dimension 2 (Dim2)**:
    -   Captures the variance primarily explained by Quantity.
    -   A high score on Dim2 indicates higher Quantity.

### Practical Implications:

1.  **Sales and Profit**:
    -   These two variables are strongly positively correlated, meaning that as sales increase, profits also increase, which is expected in most business contexts.
2.  **Discount**:
    -   There is a strong inverse relationship between Discount and both Sales and Profit, suggesting that higher discounts might be associated with lower sales and profit.
3.  **Quantity**:
    -   Quantity has a different pattern compared to the other variables, indicating it captures a unique aspect of the data variability.

### Conclusion:

The PCA plot provides a clear visualization of the relationships between Sales, Profit, Discount, and Quantity.

It shows that Sales and Profit are positively correlated and both inversely related to Discount.

Quantity contributes to the second dimension, indicating its unique contribution to the overall variance.

This analysis helps in understanding the underlying structure of the data and can guide further decision-making and strategic planning.

### 6. Time Series Decomposition

**Introduction**: - Time series decomposition separates a time series into trend, seasonal, and residual components, which helps understand underlying patterns in the data.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(ggplot2) 
library(forecast)  

# Ensure the 'Order Date' column is in Date format
superstore <- superstore %>%
  mutate(`Order Date` = as.Date(`Order Date`, format = "%m/%d/%Y"))  # Adjust the format as needed

# Aggregate sales data by month 
monthly_sales <- superstore %>% 
  group_by(Month = format(`Order Date`, "%Y-%m")) %>%   
  summarise(Total_Sales = sum(Sales))  

# Convert to time series object 
sales_ts <- ts(monthly_sales$Total_Sales, start = c(2014, 1), frequency = 12)  

# Decompose time series 
decomposed <- decompose(sales_ts)  

# Plot decomposition 
autoplot(decomposed)
```

The image shows the results of a time series decomposition of total sales, separating the time series into trend, seasonal, and residual components. Here is the interpretation of each component shown in the decomposition plot:

### Interpretation of the Decomposition Plot:

1.  **Data**:
    -   The top panel shows the original time series data for total sales from 2014 to 2018.
    -   This represents the raw data with all its variability, including trends, seasonality, and random noise.
2.  **Trend**:
    -   The second panel shows the trend component, which captures the long-term movement in the data.
    -   The trend indicates that total sales have been generally increasing over the period, with some fluctuations.
    -   The increase is more noticeable starting around mid-2015 and continues upwards towards the end of 2017.
3.  **Seasonal**:
    -   The third panel shows the seasonal component, which captures the repeating patterns or cycles within a year.
    -   There are clear seasonal fluctuations in sales, with peaks and troughs repeating annually.
    -   The seasonality indicates that sales tend to be higher at certain times of the year and lower at others, following a consistent pattern each year.
4.  **Remainder (Residual)**:
    -   The bottom panel shows the remainder component, which captures the irregular fluctuations after removing the trend and seasonal components.
    -   These are the random noise or unexpected variations in the data.
    -   The residuals should ideally have no clear pattern and be randomly distributed around zero.

### Practical Implications:

1.  **Understanding Trends**:
    -   The upward trend indicates that total sales have been increasing over the analyzed period. This positive trend is a good sign for business growth.
2.  **Seasonal Patterns**:
    -   The presence of clear seasonal patterns suggests that certain times of the year consistently experience higher or lower sales.
    -   Understanding these patterns can help in planning inventory, marketing campaigns, and resource allocation to maximize sales during peak periods and manage lower sales periods effectively.
3.  **Managing Irregular Variations**:
    -   By isolating the residual component, businesses can identify unusual fluctuations that are not explained by the trend or seasonal patterns.
    -   Analyzing these residuals can help in identifying specific events or anomalies that impact sales, allowing for more targeted interventions.

### Conclusion:

The time series decomposition provides valuable insights into the underlying patterns in the total sales data.

The increasing trend indicates overall growth, while the seasonal component reveals regular fluctuations throughout the year.

The residual component highlights the random noise, helping to isolate and understand irregular variations.

These insights can guide strategic planning, resource allocation, and marketing efforts to optimize sales performance.

### 7. Survival Analysis

**Introduction**: - Survival analysis estimates the expected duration of time until one or more events occur, such as customer churn.

**R Code**:

```{r}
# Load necessary libraries 
library(dplyr) 
library(survival) 
library(ggplot2) 
library(survminer)  
  
# Assume we have a customer data frame with columns: Customer_ID, Order_Date, and Churn (1 if churn, 0 if not)
  
# Create a sequence of dates from January 2014 to December 2017
order_dates <- seq(as.Date("2014-01-01"), as.Date("2017-12-31"), by = "month")
  
# Repeat this sequence to ensure we have 1000 dates
order_dates <- rep(order_dates, length.out = 1000)
  
# Create a dummy dataset for illustration purposes 
customer_data <- data.frame(Customer_ID = rep(1:100, each = 10),   Order_Date = order_dates, Churn = sample(0:1, 1000, replace = TRUE) )  
  
# Create a survival object 
surv_object <- Surv(time = as.numeric(customer_data$Order_Date), event = customer_data$Churn)  
  
# Fit Kaplan-Meier survival curve 
km_fit <- survfit(surv_object ~ 1, data = customer_data)  
  
# Plot the survival curve 
ggsurvplot(km_fit, data = customer_data, xlab = "Days", ylab = "Survival Probability", title = "Kaplan-Meier Survival Curve")
```

### Interpretation of the Kaplan-Meier Survival Curve

The Kaplan-Meier survival curve shown in the plot represents the survival probability over time, where "survival" in this context refers to the probability that a customer has not churned by a given time.

#### Kaplan-Meier Survival Curve:

**Plot Description:** - **X-axis (Days):** The number of days since the beginning of the observation period. - **Y-axis (Survival Probability):** The probability that a customer has not churned (remains a customer) at a given time. - **Curve:** The survival curve shows the estimated survival probability over time. The curve starts at 1 (or 100%) and decreases as customers churn over time. - **Strata Legend:** Indicates that all customers are considered together without stratification.

**Key Observations:** 1. **Initial Survival Probability:** - At the start (time = 0), the survival probability is 1, meaning all customers are active.

2.  **Survival over Time:**
    -   The curve remains flat at 1 for a significant portion of the time, indicating that customers did not churn during this period.
    -   Towards the end of the observation period (around 15,000 days), the curve starts to decline, indicating an increase in churn events.
3.  **Final Survival Probability:**
    -   The survival probability drops sharply at the end, reflecting a higher rate of churn as the time progresses towards the end of the observation period.
    -   This sharp decline might be due to the data structure, suggesting that many customers are recorded as having churned towards the end of the observation period.

**Interpretation:** - **Low Churn in Initial and Middle Periods:** The flat survival curve for most of the observation period suggests that customers tend to stay with the company for a long duration without churning. - **Increased Churn at the End:** The sharp decline towards the end indicates a significant increase in churn events, possibly due to the duration of the study or a specific time-related factor affecting customer retention. - **Overall Survival Probability:** The general shape of the curve suggests that the majority of the customers remain with the company until the end of the observation period.

**Practical Implications:** - **Retention Strategies:** Given the low churn in the initial and middle periods, efforts to retain customers should focus on understanding and mitigating the factors that lead to the increased churn towards the end. - **Further Analysis:** Investigate why churn rates increase towards the end of the observation period. This could involve looking at customer feedback, changes in service, market conditions, or other external factors. - **Targeted Interventions:** Develop targeted interventions for customers who are approaching the end of the observation period to prevent churn, based on the identified factors.

### Conclusion

The Kaplan-Meier survival curve provides a visual representation of customer retention over time, showing a high retention rate initially and a significant increase in churn towards the end. This information can be used to guide strategies aimed at improving customer retention and understanding the factors driving churn.
